"""
æ•°æ®åŒæ­¥ç›¸å…³çš„å®šæ—¶ä»»åŠ¡
"""
import sys
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any
import asyncio

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', '..'))

from celery import current_task
from tasks.celery_app import celery_app
# æš‚æ—¶ä½¿ç”¨ç®€å•çš„æ—¥å¿—è®°å½•
import logging
logger = logging.getLogger(__name__)

# å¯¼å…¥æ•°æ®åº“è®¿é—®å±‚
try:
    from backend.shared.database.mongodb import get_db_manager, get_stock_repository

    async def get_async_db_manager():
        return await get_db_manager()

    async def get_async_stock_repository():
        return await get_stock_repository()

except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå‡½æ•°
    async def get_async_db_manager():
        return None

    async def get_async_stock_repository():
        return None

# å¯¼å…¥ç°æœ‰çš„æ•°æ®è·å–é€»è¾‘
try:
    from tradingagents.dataflows.interface import (
        get_china_stock_data_unified,
        get_china_stock_info_unified,
        get_stock_fundamentals_unified,
        get_stock_news_unified
    )
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå‡½æ•°
    def get_china_stock_data_unified(*args, **kwargs):
        return "æ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®"
    
    def get_china_stock_info_unified(*args, **kwargs):
        return {"symbol": "000001", "name": "æ¨¡æ‹Ÿè‚¡ç¥¨"}
    
    def get_stock_fundamentals_unified(*args, **kwargs):
        return "æ¨¡æ‹Ÿè´¢åŠ¡æ•°æ®"
    
    def get_stock_news_unified(*args, **kwargs):
        return "æ¨¡æ‹Ÿæ–°é—»æ•°æ®"

# logger å·²åœ¨ä¸Šé¢å®šä¹‰


def run_async_task(coro):
    """è¿è¡Œå¼‚æ­¥ä»»åŠ¡çš„è¾…åŠ©å‡½æ•°"""
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    
    return loop.run_until_complete(coro)


@celery_app.task(bind=True, name='tasks.data_tasks.sync_daily_stock_data')
def sync_daily_stock_data(self, symbols: List[str] = None, date: str = None):
    """
    åŒæ­¥æ¯æ—¥è‚¡ç¥¨æ•°æ®
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œä¸ºç©ºåˆ™åŒæ­¥æ‰€æœ‰è‚¡ç¥¨
        date: æŒ‡å®šæ—¥æœŸï¼Œä¸ºç©ºåˆ™ä½¿ç”¨æ˜¨æ—¥
    """
    task_id = self.request.id
    logger.info(f"ğŸš€ å¼€å§‹åŒæ­¥æ¯æ—¥è‚¡ç¥¨æ•°æ® - ä»»åŠ¡ID: {task_id}")
    
    try:
        # è®¾ç½®é»˜è®¤å‚æ•°
        if date is None:
            # è·å–ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥
            target_date = datetime.now() - timedelta(days=1)
            date = target_date.strftime('%Y-%m-%d')
        
        if symbols is None:
            # è·å–æ‰€æœ‰Aè‚¡ä»£ç ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
            symbols = ['000001', '000002', '600519', '000858']  # ç¤ºä¾‹è‚¡ç¥¨
        
        logger.info(f"ğŸ“Š åŒæ­¥å‚æ•°: æ—¥æœŸ={date}, è‚¡ç¥¨æ•°é‡={len(symbols)}")
        
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        self.update_state(
            state='PROGRESS',
            meta={'current': 0, 'total': len(symbols), 'status': 'å¼€å§‹åŒæ­¥æ•°æ®'}
        )
        
        async def sync_data():
            db_manager = await get_async_db_manager()
            stock_repo = await get_async_stock_repository()
            
            success_count = 0
            error_count = 0
            
            for i, symbol in enumerate(symbols):
                try:
                    logger.info(f"ğŸ“ˆ åŒæ­¥è‚¡ç¥¨æ•°æ®: {symbol}")
                    
                    # è·å–è‚¡ç¥¨æ•°æ®
                    start_date = date
                    end_date = date
                    
                    stock_data = get_china_stock_data_unified(symbol, start_date, end_date)
                    
                    if stock_data and "é”™è¯¯" not in str(stock_data):
                        # è§£æå¹¶ä¿å­˜æ•°æ®ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®æ ¼å¼è°ƒæ•´ï¼‰
                        parsed_data = [{
                            'trade_date': datetime.strptime(date, '%Y-%m-%d'),
                            'open': 100.0,  # ä»stock_dataè§£æ
                            'high': 105.0,
                            'low': 98.0,
                            'close': 102.0,
                            'volume': 1000000,
                            'amount': 102000000.0
                        }]
                        
                        await stock_repo.save_stock_daily_data(symbol, parsed_data)
                        success_count += 1
                        logger.info(f"âœ… {symbol} æ•°æ®åŒæ­¥æˆåŠŸ")
                    else:
                        error_count += 1
                        logger.warning(f"âš ï¸ {symbol} æ•°æ®è·å–å¤±è´¥: {stock_data}")
                    
                    # æ›´æ–°è¿›åº¦
                    self.update_state(
                        state='PROGRESS',
                        meta={
                            'current': i + 1,
                            'total': len(symbols),
                            'status': f'å·²å¤„ç† {i + 1}/{len(symbols)} åªè‚¡ç¥¨',
                            'success': success_count,
                            'errors': error_count
                        }
                    )
                    
                except Exception as e:
                    error_count += 1
                    logger.error(f"âŒ {symbol} åŒæ­¥å¤±è´¥: {e}")
            
            await db_manager.disconnect()
            return success_count, error_count
        
        # æ‰§è¡Œå¼‚æ­¥ä»»åŠ¡
        success_count, error_count = run_async_task(sync_data())
        
        result = {
            'date': date,
            'total_symbols': len(symbols),
            'success_count': success_count,
            'error_count': error_count,
            'completion_time': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… æ¯æ—¥è‚¡ç¥¨æ•°æ®åŒæ­¥å®Œæˆ: æˆåŠŸ{success_count}ä¸ª, å¤±è´¥{error_count}ä¸ª")
        return result
        
    except Exception as e:
        logger.error(f"âŒ æ¯æ—¥è‚¡ç¥¨æ•°æ®åŒæ­¥å¤±è´¥: {e}")
        self.update_state(
            state='FAILURE',
            meta={'error': str(e), 'traceback': str(e)}
        )
        raise


@celery_app.task(bind=True, name='tasks.data_tasks.update_realtime_prices')
def update_realtime_prices(self, symbols: List[str] = None):
    """
    æ›´æ–°å®æ—¶è‚¡ä»·
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    task_id = self.request.id
    logger.info(f"âš¡ å¼€å§‹æ›´æ–°å®æ—¶è‚¡ä»· - ä»»åŠ¡ID: {task_id}")
    
    try:
        # æ£€æŸ¥æ˜¯å¦åœ¨äº¤æ˜“æ—¶é—´
        now = datetime.now()
        if now.hour < 9 or now.hour > 15:
            logger.info("â° éäº¤æ˜“æ—¶é—´ï¼Œè·³è¿‡å®æ—¶ä»·æ ¼æ›´æ–°")
            return {'status': 'skipped', 'reason': 'éäº¤æ˜“æ—¶é—´'}
        
        if symbols is None:
            symbols = ['000001', '000002', '600519', '000858']  # çƒ­é—¨è‚¡ç¥¨
        
        async def update_prices():
            # è¿™é‡Œå®ç°å®æ—¶ä»·æ ¼æ›´æ–°é€»è¾‘
            # å¯ä»¥è°ƒç”¨å®æ—¶æ•°æ®APIï¼Œæ›´æ–°Redisç¼“å­˜
            updated_count = 0
            
            for symbol in symbols:
                try:
                    # è·å–å®æ—¶ä»·æ ¼ï¼ˆæ¨¡æ‹Ÿï¼‰
                    current_price = 100.0  # ä»APIè·å–
                    
                    # æ›´æ–°ç¼“å­˜
                    # await redis_client.setex(f"price:{symbol}", 300, current_price)
                    
                    updated_count += 1
                    logger.debug(f"ğŸ“Š æ›´æ–° {symbol} å®æ—¶ä»·æ ¼: {current_price}")
                    
                except Exception as e:
                    logger.error(f"âŒ æ›´æ–° {symbol} å®æ—¶ä»·æ ¼å¤±è´¥: {e}")
            
            return updated_count
        
        updated_count = run_async_task(update_prices())
        
        result = {
            'updated_count': updated_count,
            'total_symbols': len(symbols),
            'update_time': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… å®æ—¶è‚¡ä»·æ›´æ–°å®Œæˆ: {updated_count}/{len(symbols)}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ å®æ—¶è‚¡ä»·æ›´æ–°å¤±è´¥: {e}")
        raise


@celery_app.task(bind=True, name='tasks.data_tasks.sync_financial_data')
def sync_financial_data(self, symbols: List[str] = None):
    """
    åŒæ­¥è´¢åŠ¡æ•°æ®
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
    """
    task_id = self.request.id
    logger.info(f"ğŸ’° å¼€å§‹åŒæ­¥è´¢åŠ¡æ•°æ® - ä»»åŠ¡ID: {task_id}")
    
    try:
        if symbols is None:
            symbols = ['000001', '000002', '600519', '000858']
        
        async def sync_financials():
            success_count = 0
            
            for symbol in symbols:
                try:
                    # è·å–è´¢åŠ¡æ•°æ®
                    current_date = datetime.now().strftime('%Y-%m-%d')
                    start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')
                    
                    financial_data = get_stock_fundamentals_unified(
                        symbol, start_date, current_date, current_date
                    )
                    
                    if financial_data and "é”™è¯¯" not in str(financial_data):
                        # ä¿å­˜è´¢åŠ¡æ•°æ®åˆ°æ•°æ®åº“
                        success_count += 1
                        logger.info(f"âœ… {symbol} è´¢åŠ¡æ•°æ®åŒæ­¥æˆåŠŸ")
                    else:
                        logger.warning(f"âš ï¸ {symbol} è´¢åŠ¡æ•°æ®è·å–å¤±è´¥")
                        
                except Exception as e:
                    logger.error(f"âŒ {symbol} è´¢åŠ¡æ•°æ®åŒæ­¥å¤±è´¥: {e}")
            
            return success_count
        
        success_count = run_async_task(sync_financials())
        
        result = {
            'success_count': success_count,
            'total_symbols': len(symbols),
            'sync_time': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… è´¢åŠ¡æ•°æ®åŒæ­¥å®Œæˆ: {success_count}/{len(symbols)}")
        return result
        
    except Exception as e:
        logger.error(f"âŒ è´¢åŠ¡æ•°æ®åŒæ­¥å¤±è´¥: {e}")
        raise


@celery_app.task(bind=True, name='tasks.data_tasks.fetch_news_data')
def fetch_news_data(self, symbols: List[str] = None, limit: int = 50):
    """
    æŠ“å–æ–°é—»æ•°æ®
    
    Args:
        symbols: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        limit: æ¯åªè‚¡ç¥¨çš„æ–°é—»æ•°é‡é™åˆ¶
    """
    task_id = self.request.id
    logger.info(f"ğŸ“° å¼€å§‹æŠ“å–æ–°é—»æ•°æ® - ä»»åŠ¡ID: {task_id}")
    
    try:
        if symbols is None:
            symbols = ['000001', '000002', '600519', '000858']
        
        async def fetch_news():
            total_news = 0
            
            for symbol in symbols:
                try:
                    # è·å–æ–°é—»æ•°æ®
                    news_data = get_stock_news_unified(symbol)
                    
                    if news_data and "é”™è¯¯" not in str(news_data):
                        # è§£æå¹¶ä¿å­˜æ–°é—»æ•°æ®
                        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®æ ¼å¼è¿›è¡Œè§£æ
                        news_count = 10  # æ¨¡æ‹Ÿæ–°é—»æ•°é‡
                        total_news += news_count
                        logger.info(f"âœ… {symbol} æ–°é—»æ•°æ®æŠ“å–æˆåŠŸ: {news_count}æ¡")
                    else:
                        logger.warning(f"âš ï¸ {symbol} æ–°é—»æ•°æ®è·å–å¤±è´¥")
                        
                except Exception as e:
                    logger.error(f"âŒ {symbol} æ–°é—»æ•°æ®æŠ“å–å¤±è´¥: {e}")
            
            return total_news
        
        total_news = run_async_task(fetch_news())
        
        result = {
            'total_news': total_news,
            'symbols_count': len(symbols),
            'fetch_time': datetime.now().isoformat()
        }
        
        logger.info(f"âœ… æ–°é—»æ•°æ®æŠ“å–å®Œæˆ: å…±{total_news}æ¡æ–°é—»")
        return result
        
    except Exception as e:
        logger.error(f"âŒ æ–°é—»æ•°æ®æŠ“å–å¤±è´¥: {e}")
        raise
