"""
å¹¶å‘ç®¡ç†å™¨
ç®¡ç†åˆ†æä»»åŠ¡çš„å¹¶å‘æ‰§è¡Œã€é˜Ÿåˆ—è°ƒåº¦å’Œèµ„æºæ§åˆ¶
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime, timedelta
from enum import Enum
import uuid
from dataclasses import dataclass, field
from collections import defaultdict
import time

logger = logging.getLogger(__name__)

class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    URGENT = 4

class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class AnalysisTask:
    """åˆ†æä»»åŠ¡"""
    task_id: str
    stock_code: str
    analysis_type: str
    priority: TaskPriority = TaskPriority.NORMAL
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    status: TaskStatus = TaskStatus.PENDING
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    retry_count: int = 0
    max_retries: int = 3
    timeout: int = 300  # 5åˆ†é’Ÿè¶…æ—¶
    metadata: Dict[str, Any] = field(default_factory=dict)

class ConcurrencyManager:
    """å¹¶å‘ç®¡ç†å™¨"""
    
    def __init__(self, max_concurrent_tasks: int = 10, max_queue_size: int = 100):
        self.max_concurrent_tasks = max_concurrent_tasks
        self.max_queue_size = max_queue_size
        
        # å¹¶å‘æ§åˆ¶
        self.semaphore = asyncio.Semaphore(max_concurrent_tasks)
        self.running_tasks: Dict[str, AnalysisTask] = {}
        self.task_queue: List[AnalysisTask] = []
        self.completed_tasks: Dict[str, AnalysisTask] = {}
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "total_submitted": 0,
            "total_completed": 0,
            "total_failed": 0,
            "total_cancelled": 0,
            "current_running": 0,
            "current_queued": 0,
            "average_execution_time": 0.0,
            "peak_concurrent_tasks": 0
        }
        
        # æ€§èƒ½ç›‘æ§
        self.execution_times: List[float] = []
        self.start_time = datetime.now()
        
        # ä»»åŠ¡å¤„ç†å™¨
        self.task_processor: Optional[Callable] = None
        
        logger.info(f"ğŸ”„ å¹¶å‘ç®¡ç†å™¨åˆå§‹åŒ–: æœ€å¤§å¹¶å‘{max_concurrent_tasks}, é˜Ÿåˆ—å¤§å°{max_queue_size}")
    
    def set_task_processor(self, processor: Callable):
        """è®¾ç½®ä»»åŠ¡å¤„ç†å™¨"""
        self.task_processor = processor
        logger.info("âœ… ä»»åŠ¡å¤„ç†å™¨å·²è®¾ç½®")
    
    async def submit_task(self, stock_code: str, analysis_type: str, 
                         priority: TaskPriority = TaskPriority.NORMAL,
                         metadata: Optional[Dict[str, Any]] = None) -> str:
        """æäº¤åˆ†æä»»åŠ¡"""
        
        # æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²æ»¡
        if len(self.task_queue) >= self.max_queue_size:
            raise Exception(f"ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡ (æœ€å¤§{self.max_queue_size})")
        
        # åˆ›å»ºä»»åŠ¡
        task_id = str(uuid.uuid4())
        task = AnalysisTask(
            task_id=task_id,
            stock_code=stock_code,
            analysis_type=analysis_type,
            priority=priority,
            metadata=metadata or {}
        )
        
        # æ·»åŠ åˆ°é˜Ÿåˆ—
        self._add_to_queue(task)
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats["total_submitted"] += 1
        self.stats["current_queued"] = len(self.task_queue)
        
        logger.info(f"ğŸ“‹ ä»»åŠ¡å·²æäº¤: {task_id} - {stock_code} ({analysis_type})")
        
        # å°è¯•ç«‹å³å¤„ç†
        asyncio.create_task(self._process_queue())
        
        return task_id
    
    def _add_to_queue(self, task: AnalysisTask):
        """æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰"""
        self.task_queue.append(task)
        
        # æŒ‰ä¼˜å…ˆçº§æ’åºï¼ˆä¼˜å…ˆçº§é«˜çš„åœ¨å‰ï¼‰
        self.task_queue.sort(key=lambda t: t.priority.value, reverse=True)
    
    async def _process_queue(self):
        """å¤„ç†ä»»åŠ¡é˜Ÿåˆ—"""
        while self.task_queue and len(self.running_tasks) < self.max_concurrent_tasks:
            # è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡
            task = self.task_queue.pop(0)
            
            # å¯åŠ¨ä»»åŠ¡
            asyncio.create_task(self._execute_task(task))
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats["current_queued"] = len(self.task_queue)
    
    async def _execute_task(self, task: AnalysisTask):
        """æ‰§è¡Œå•ä¸ªä»»åŠ¡"""
        async with self.semaphore:
            try:
                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                task.status = TaskStatus.RUNNING
                task.started_at = datetime.now()
                self.running_tasks[task.task_id] = task
                
                # æ›´æ–°ç»Ÿè®¡
                self.stats["current_running"] = len(self.running_tasks)
                self.stats["peak_concurrent_tasks"] = max(
                    self.stats["peak_concurrent_tasks"],
                    len(self.running_tasks)
                )
                
                logger.info(f"ğŸš€ å¼€å§‹æ‰§è¡Œä»»åŠ¡: {task.task_id} - {task.stock_code}")
                
                # æ‰§è¡Œä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼‰
                result = await asyncio.wait_for(
                    self._run_analysis_task(task),
                    timeout=task.timeout
                )
                
                # ä»»åŠ¡å®Œæˆ
                task.status = TaskStatus.COMPLETED
                task.completed_at = datetime.now()
                task.result = result
                
                # è®°å½•æ‰§è¡Œæ—¶é—´
                execution_time = (task.completed_at - task.started_at).total_seconds()
                self.execution_times.append(execution_time)
                
                # æ›´æ–°ç»Ÿè®¡
                self.stats["total_completed"] += 1
                self._update_average_execution_time()
                
                logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {task.task_id} - è€—æ—¶{execution_time:.1f}s")
                
            except asyncio.TimeoutError:
                # ä»»åŠ¡è¶…æ—¶
                task.status = TaskStatus.FAILED
                task.error = f"ä»»åŠ¡è¶…æ—¶ ({task.timeout}s)"
                task.completed_at = datetime.now()
                
                self.stats["total_failed"] += 1
                logger.error(f"â° ä»»åŠ¡è¶…æ—¶: {task.task_id}")
                
            except Exception as e:
                # ä»»åŠ¡å¤±è´¥
                task.status = TaskStatus.FAILED
                task.error = str(e)
                task.completed_at = datetime.now()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
                if task.retry_count < task.max_retries:
                    task.retry_count += 1
                    task.status = TaskStatus.PENDING
                    task.started_at = None
                    task.completed_at = None
                    task.error = None
                    
                    # é‡æ–°åŠ å…¥é˜Ÿåˆ—
                    self._add_to_queue(task)
                    logger.warning(f"ğŸ”„ ä»»åŠ¡é‡è¯•: {task.task_id} (ç¬¬{task.retry_count}æ¬¡)")
                else:
                    self.stats["total_failed"] += 1
                    logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {task.task_id} - {e}")
                
            finally:
                # æ¸…ç†è¿è¡Œä¸­çš„ä»»åŠ¡
                if task.task_id in self.running_tasks:
                    del self.running_tasks[task.task_id]
                
                # ç§»åŠ¨åˆ°å®Œæˆåˆ—è¡¨
                self.completed_tasks[task.task_id] = task
                
                # æ›´æ–°ç»Ÿè®¡
                self.stats["current_running"] = len(self.running_tasks)
                
                # ç»§ç»­å¤„ç†é˜Ÿåˆ—
                asyncio.create_task(self._process_queue())
    
    async def _run_analysis_task(self, task: AnalysisTask) -> Dict[str, Any]:
        """è¿è¡Œåˆ†æä»»åŠ¡"""
        if not self.task_processor:
            raise Exception("ä»»åŠ¡å¤„ç†å™¨æœªè®¾ç½®")
        
        # è°ƒç”¨å®é™…çš„åˆ†æå¤„ç†å™¨
        return await self.task_processor(
            stock_code=task.stock_code,
            analysis_type=task.analysis_type,
            metadata=task.metadata
        )
    
    def _update_average_execution_time(self):
        """æ›´æ–°å¹³å‡æ‰§è¡Œæ—¶é—´"""
        if self.execution_times:
            self.stats["average_execution_time"] = sum(self.execution_times) / len(self.execution_times)
    
    async def get_task_status(self, task_id: str) -> Optional[AnalysisTask]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        # æ£€æŸ¥è¿è¡Œä¸­çš„ä»»åŠ¡
        if task_id in self.running_tasks:
            return self.running_tasks[task_id]
        
        # æ£€æŸ¥å®Œæˆçš„ä»»åŠ¡
        if task_id in self.completed_tasks:
            return self.completed_tasks[task_id]
        
        # æ£€æŸ¥é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        for task in self.task_queue:
            if task.task_id == task_id:
                return task
        
        return None
    
    async def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡"""
        # ä»é˜Ÿåˆ—ä¸­ç§»é™¤
        for i, task in enumerate(self.task_queue):
            if task.task_id == task_id:
                task.status = TaskStatus.CANCELLED
                task.completed_at = datetime.now()
                self.task_queue.pop(i)
                self.completed_tasks[task_id] = task
                self.stats["total_cancelled"] += 1
                self.stats["current_queued"] = len(self.task_queue)
                logger.info(f"ğŸš« ä»»åŠ¡å·²å–æ¶ˆ: {task_id}")
                return True
        
        # è¿è¡Œä¸­çš„ä»»åŠ¡æ— æ³•å–æ¶ˆï¼ˆå¯ä»¥è€ƒè™‘å®ç°ä¸­æ–­æœºåˆ¶ï¼‰
        if task_id in self.running_tasks:
            logger.warning(f"âš ï¸ è¿è¡Œä¸­çš„ä»»åŠ¡æ— æ³•å–æ¶ˆ: {task_id}")
            return False
        
        return False
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        uptime = (datetime.now() - self.start_time).total_seconds()
        
        return {
            **self.stats,
            "uptime_seconds": uptime,
            "tasks_per_minute": (self.stats["total_completed"] / uptime * 60) if uptime > 0 else 0,
            "success_rate": (
                self.stats["total_completed"] / 
                (self.stats["total_completed"] + self.stats["total_failed"])
                if (self.stats["total_completed"] + self.stats["total_failed"]) > 0 else 0
            ),
            "queue_utilization": len(self.task_queue) / self.max_queue_size,
            "concurrency_utilization": len(self.running_tasks) / self.max_concurrent_tasks
        }
    
    def get_queue_status(self) -> Dict[str, Any]:
        """è·å–é˜Ÿåˆ—çŠ¶æ€"""
        queue_by_priority = defaultdict(int)
        for task in self.task_queue:
            queue_by_priority[task.priority.name] += 1
        
        return {
            "total_queued": len(self.task_queue),
            "total_running": len(self.running_tasks),
            "queue_by_priority": dict(queue_by_priority),
            "running_tasks": [
                {
                    "task_id": task.task_id,
                    "stock_code": task.stock_code,
                    "analysis_type": task.analysis_type,
                    "started_at": task.started_at.isoformat() if task.started_at else None,
                    "running_time": (
                        (datetime.now() - task.started_at).total_seconds() 
                        if task.started_at else 0
                    )
                }
                for task in self.running_tasks.values()
            ]
        }
    
    async def cleanup_completed_tasks(self, max_age_hours: int = 24):
        """æ¸…ç†å®Œæˆçš„ä»»åŠ¡"""
        cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
        
        to_remove = []
        for task_id, task in self.completed_tasks.items():
            if task.completed_at and task.completed_at < cutoff_time:
                to_remove.append(task_id)
        
        for task_id in to_remove:
            del self.completed_tasks[task_id]
        
        if to_remove:
            logger.info(f"ğŸ§¹ æ¸…ç†äº†{len(to_remove)}ä¸ªè¿‡æœŸä»»åŠ¡")
    
    async def shutdown(self):
        """å…³é—­å¹¶å‘ç®¡ç†å™¨"""
        logger.info("ğŸ”„ å…³é—­å¹¶å‘ç®¡ç†å™¨...")
        
        # å–æ¶ˆæ‰€æœ‰é˜Ÿåˆ—ä¸­çš„ä»»åŠ¡
        for task in self.task_queue:
            task.status = TaskStatus.CANCELLED
            task.completed_at = datetime.now()
            self.completed_tasks[task.task_id] = task
        
        self.task_queue.clear()
        
        # ç­‰å¾…è¿è¡Œä¸­çš„ä»»åŠ¡å®Œæˆ
        while self.running_tasks:
            logger.info(f"â³ ç­‰å¾…{len(self.running_tasks)}ä¸ªä»»åŠ¡å®Œæˆ...")
            await asyncio.sleep(1)
        
        logger.info("âœ… å¹¶å‘ç®¡ç†å™¨å·²å…³é—­")

# å…¨å±€å¹¶å‘ç®¡ç†å™¨å®ä¾‹
_concurrency_manager: Optional[ConcurrencyManager] = None

def get_concurrency_manager(max_concurrent_tasks: int = 10, max_queue_size: int = 100) -> ConcurrencyManager:
    """è·å–å…¨å±€å¹¶å‘ç®¡ç†å™¨å®ä¾‹"""
    global _concurrency_manager
    
    if _concurrency_manager is None:
        _concurrency_manager = ConcurrencyManager(max_concurrent_tasks, max_queue_size)
    
    return _concurrency_manager

async def shutdown_concurrency_manager():
    """å…³é—­å…¨å±€å¹¶å‘ç®¡ç†å™¨"""
    global _concurrency_manager
    
    if _concurrency_manager:
        await _concurrency_manager.shutdown()
        _concurrency_manager = None
