#!/usr/bin/env python3
"""
æç¤ºè¯ç®¡ç†å™¨
æ”¯æŒå¤šæ¨¡å‹ã€å¤šä»»åŠ¡ã€å¤šè¯­è¨€çš„æç¤ºè¯ç®¡ç†
"""

import json
import yaml
import logging
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import asyncio

logger = logging.getLogger(__name__)

class PromptTemplate:
    """æç¤ºè¯æ¨¡æ¿"""
    
    def __init__(self, template_data: Dict[str, Any]):
        self.id = template_data.get("id")
        self.name = template_data.get("name")
        self.description = template_data.get("description")
        self.version = template_data.get("version", "1.0")
        self.language = template_data.get("language", "zh")
        self.task_type = template_data.get("task_type")
        self.model_type = template_data.get("model_type", "general")
        self.system_prompt = template_data.get("system_prompt", "")
        self.user_prompt_template = template_data.get("user_prompt_template", "")
        self.variables = template_data.get("variables", [])
        self.examples = template_data.get("examples", [])
        self.created_at = template_data.get("created_at", datetime.now().isoformat())
        self.updated_at = template_data.get("updated_at", datetime.now().isoformat())
    
    def format_prompt(self, variables: Dict[str, Any] = None) -> Tuple[str, str]:
        """
        æ ¼å¼åŒ–æç¤ºè¯
        
        Returns:
            (system_prompt, user_prompt)
        """
        variables = variables or {}
        
        try:
            # æ ¼å¼åŒ–ç³»ç»Ÿæç¤ºè¯
            system_prompt = self.system_prompt.format(**variables)
            
            # æ ¼å¼åŒ–ç”¨æˆ·æç¤ºè¯
            user_prompt = self.user_prompt_template.format(**variables)
            
            return system_prompt, user_prompt
            
        except KeyError as e:
            logger.error(f"æç¤ºè¯å˜é‡ç¼ºå¤±: {e}")
            raise ValueError(f"æç¤ºè¯å˜é‡ç¼ºå¤±: {e}")
    
    def validate_variables(self, variables: Dict[str, Any]) -> List[str]:
        """éªŒè¯å˜é‡æ˜¯å¦å®Œæ•´"""
        missing_vars = []
        for var in self.variables:
            var_name = var.get("name")
            if var.get("required", True) and var_name not in variables:
                missing_vars.append(var_name)
        return missing_vars
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "id": self.id,
            "name": self.name,
            "description": self.description,
            "version": self.version,
            "language": self.language,
            "task_type": self.task_type,
            "model_type": self.model_type,
            "system_prompt": self.system_prompt,
            "user_prompt_template": self.user_prompt_template,
            "variables": self.variables,
            "examples": self.examples,
            "created_at": self.created_at,
            "updated_at": self.updated_at
        }

class PromptManager:
    """æç¤ºè¯ç®¡ç†å™¨"""
    
    def __init__(self, prompts_dir: str = None):
        self.prompts_dir = Path(prompts_dir or Path(__file__).parent / "templates")
        self.templates: Dict[str, PromptTemplate] = {}
        self.model_mappings: Dict[str, Dict[str, str]] = {}
        self._last_reload = None
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.prompts_dir.mkdir(parents=True, exist_ok=True)
    
    async def load_templates(self):
        """åŠ è½½æ‰€æœ‰æç¤ºè¯æ¨¡æ¿"""
        logger.info(f"ğŸ”„ åŠ è½½æç¤ºè¯æ¨¡æ¿: {self.prompts_dir}")
        
        try:
            # æ¸…ç©ºç°æœ‰æ¨¡æ¿
            self.templates.clear()
            
            # åŠ è½½æ¨¡æ¿æ–‡ä»¶
            template_files = list(self.prompts_dir.glob("**/*.yaml")) + list(self.prompts_dir.glob("**/*.yml"))
            
            for template_file in template_files:
                try:
                    with open(template_file, 'r', encoding='utf-8') as f:
                        template_data = yaml.safe_load(f)
                    
                    # æ”¯æŒå•ä¸ªæ¨¡æ¿æˆ–å¤šä¸ªæ¨¡æ¿
                    if isinstance(template_data, list):
                        for item in template_data:
                            template = PromptTemplate(item)
                            self.templates[template.id] = template
                    else:
                        template = PromptTemplate(template_data)
                        self.templates[template.id] = template
                    
                    logger.debug(f"âœ… åŠ è½½æ¨¡æ¿: {template_file.name}")
                    
                except Exception as e:
                    logger.error(f"âŒ åŠ è½½æ¨¡æ¿å¤±è´¥ {template_file}: {e}")
            
            # åŠ è½½æ¨¡å‹æ˜ å°„é…ç½®
            await self._load_model_mappings()
            
            self._last_reload = datetime.now()
            logger.info(f"âœ… æç¤ºè¯æ¨¡æ¿åŠ è½½å®Œæˆï¼Œå…±{len(self.templates)}ä¸ªæ¨¡æ¿")
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æç¤ºè¯æ¨¡æ¿å¤±è´¥: {e}")
    
    async def _load_model_mappings(self):
        """åŠ è½½æ¨¡å‹æ˜ å°„é…ç½®"""
        mapping_file = self.prompts_dir / "model_mappings.yaml"
        
        if mapping_file.exists():
            try:
                with open(mapping_file, 'r', encoding='utf-8') as f:
                    self.model_mappings = yaml.safe_load(f) or {}
                logger.info(f"âœ… åŠ è½½æ¨¡å‹æ˜ å°„é…ç½®: {len(self.model_mappings)}ä¸ªæ¨¡å‹")
            except Exception as e:
                logger.error(f"âŒ åŠ è½½æ¨¡å‹æ˜ å°„é…ç½®å¤±è´¥: {e}")
                self.model_mappings = {}
        else:
            # åˆ›å»ºé»˜è®¤æ˜ å°„é…ç½®
            await self._create_default_model_mappings()
    
    async def _create_default_model_mappings(self):
        """åˆ›å»ºé»˜è®¤æ¨¡å‹æ˜ å°„é…ç½®"""
        default_mappings = {
            "deepseek-chat": {
                "financial_analysis": "deepseek_financial_analysis_zh",
                "code_generation": "deepseek_code_generation_zh",
                "data_extraction": "deepseek_data_extraction_zh",
                "reasoning": "deepseek_reasoning_zh",
                "general": "deepseek_general_zh"
            },
            "gpt-4": {
                "financial_analysis": "openai_financial_analysis_zh",
                "code_generation": "openai_code_generation_en",
                "data_extraction": "openai_data_extraction_zh",
                "reasoning": "openai_reasoning_zh",
                "general": "openai_general_zh"
            },
            "qwen-plus": {
                "financial_analysis": "qwen_financial_analysis_zh",
                "code_generation": "qwen_code_generation_zh",
                "data_extraction": "qwen_data_extraction_zh",
                "reasoning": "qwen_reasoning_zh",
                "general": "qwen_general_zh"
            }
        }
        
        mapping_file = self.prompts_dir / "model_mappings.yaml"
        with open(mapping_file, 'w', encoding='utf-8') as f:
            yaml.dump(default_mappings, f, allow_unicode=True, default_flow_style=False)
        
        self.model_mappings = default_mappings
        logger.info("âœ… åˆ›å»ºé»˜è®¤æ¨¡å‹æ˜ å°„é…ç½®")
    
    def get_prompt_template(self, model: str, task_type: str, language: str = "zh") -> Optional[PromptTemplate]:
        """
        è·å–æŒ‡å®šæ¨¡å‹å’Œä»»åŠ¡çš„æç¤ºè¯æ¨¡æ¿
        
        Args:
            model: æ¨¡å‹åç§°
            task_type: ä»»åŠ¡ç±»å‹
            language: è¯­è¨€
            
        Returns:
            æç¤ºè¯æ¨¡æ¿æˆ–None
        """
        # 1. å°è¯•ä»æ¨¡å‹æ˜ å°„ä¸­è·å–ç‰¹å®šæ¨¡æ¿ID
        model_config = self.model_mappings.get(model, {})
        template_id = model_config.get(task_type)
        
        if template_id and template_id in self.templates:
            return self.templates[template_id]
        
        # 2. å°è¯•é€šè¿‡æ¨¡å‹ç±»å‹å’Œä»»åŠ¡ç±»å‹åŒ¹é…
        model_type = self._get_model_type(model)
        for template in self.templates.values():
            if (template.model_type == model_type and 
                template.task_type == task_type and 
                template.language == language):
                return template
        
        # 3. å°è¯•é€šç”¨æ¨¡æ¿
        for template in self.templates.values():
            if (template.model_type == "general" and 
                template.task_type == task_type and 
                template.language == language):
                return template
        
        # 4. æœ€åå°è¯•é€šç”¨ä»»åŠ¡æ¨¡æ¿
        for template in self.templates.values():
            if (template.task_type == "general" and 
                template.language == language):
                return template
        
        logger.warning(f"âš ï¸ æœªæ‰¾åˆ°åˆé€‚çš„æç¤ºè¯æ¨¡æ¿: model={model}, task={task_type}, lang={language}")
        return None
    
    def _get_model_type(self, model: str) -> str:
        """æ ¹æ®æ¨¡å‹åç§°æ¨æ–­æ¨¡å‹ç±»å‹"""
        if "deepseek" in model.lower():
            return "deepseek"
        elif "gpt" in model.lower() or "openai" in model.lower():
            return "openai"
        elif "qwen" in model.lower() or "dashscope" in model.lower():
            return "qwen"
        elif "gemini" in model.lower() or "google" in model.lower():
            return "gemini"
        elif "claude" in model.lower():
            return "claude"
        else:
            return "general"
    
    def format_messages(self, model: str, task_type: str, variables: Dict[str, Any], 
                       language: str = "zh") -> List[Dict[str, str]]:
        """
        æ ¼å¼åŒ–æ¶ˆæ¯åˆ—è¡¨
        
        Args:
            model: æ¨¡å‹åç§°
            task_type: ä»»åŠ¡ç±»å‹
            variables: æ¨¡æ¿å˜é‡
            language: è¯­è¨€
            
        Returns:
            æ ¼å¼åŒ–åçš„æ¶ˆæ¯åˆ—è¡¨
        """
        template = self.get_prompt_template(model, task_type, language)
        
        if not template:
            # ä½¿ç”¨é»˜è®¤æç¤ºè¯
            return [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": variables.get("user_input", "")}
            ]
        
        # éªŒè¯å˜é‡
        missing_vars = template.validate_variables(variables)
        if missing_vars:
            logger.warning(f"âš ï¸ æç¤ºè¯å˜é‡ç¼ºå¤±: {missing_vars}")
        
        try:
            system_prompt, user_prompt = template.format_prompt(variables)
            
            messages = []
            if system_prompt.strip():
                messages.append({"role": "system", "content": system_prompt})
            if user_prompt.strip():
                messages.append({"role": "user", "content": user_prompt})
            
            return messages
            
        except Exception as e:
            logger.error(f"âŒ æ ¼å¼åŒ–æç¤ºè¯å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤æ¶ˆæ¯
            return [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚"},
                {"role": "user", "content": variables.get("user_input", "")}
            ]
    
    def list_templates(self, model_type: str = None, task_type: str = None, 
                      language: str = None) -> List[PromptTemplate]:
        """åˆ—å‡ºæç¤ºè¯æ¨¡æ¿"""
        templates = list(self.templates.values())
        
        if model_type:
            templates = [t for t in templates if t.model_type == model_type]
        if task_type:
            templates = [t for t in templates if t.task_type == task_type]
        if language:
            templates = [t for t in templates if t.language == language]
        
        return templates
    
    def get_template_by_id(self, template_id: str) -> Optional[PromptTemplate]:
        """æ ¹æ®IDè·å–æ¨¡æ¿"""
        return self.templates.get(template_id)
    
    async def reload_templates(self):
        """é‡æ–°åŠ è½½æ¨¡æ¿"""
        await self.load_templates()
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_templates": len(self.templates),
            "last_reload": self._last_reload.isoformat() if self._last_reload else None,
            "by_model_type": {},
            "by_task_type": {},
            "by_language": {}
        }
        
        for template in self.templates.values():
            # æŒ‰æ¨¡å‹ç±»å‹ç»Ÿè®¡
            model_type = template.model_type
            stats["by_model_type"][model_type] = stats["by_model_type"].get(model_type, 0) + 1
            
            # æŒ‰ä»»åŠ¡ç±»å‹ç»Ÿè®¡
            task_type = template.task_type
            stats["by_task_type"][task_type] = stats["by_task_type"].get(task_type, 0) + 1
            
            # æŒ‰è¯­è¨€ç»Ÿè®¡
            language = template.language
            stats["by_language"][language] = stats["by_language"].get(language, 0) + 1
        
        return stats

# å…¨å±€æç¤ºè¯ç®¡ç†å™¨å®ä¾‹
_prompt_manager_instance: Optional[PromptManager] = None

async def get_prompt_manager() -> PromptManager:
    """è·å–æç¤ºè¯ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _prompt_manager_instance
    if _prompt_manager_instance is None:
        _prompt_manager_instance = PromptManager()
        await _prompt_manager_instance.load_templates()
    return _prompt_manager_instance
