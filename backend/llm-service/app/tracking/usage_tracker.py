#!/usr/bin/env python3
"""
ä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬è·Ÿè¸ªå™¨
"""

import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
import redis.asyncio as redis

logger = logging.getLogger(__name__)

# æ¨¡å‹å®šä»·é…ç½® (USD per 1K tokens)
MODEL_PRICING = {
    "deepseek-chat": {
        "input_cost_per_1k": 0.0014,
        "output_cost_per_1k": 0.0028
    },
    "deepseek-coder": {
        "input_cost_per_1k": 0.0014,
        "output_cost_per_1k": 0.0028
    },
    "gpt-4": {
        "input_cost_per_1k": 0.03,
        "output_cost_per_1k": 0.06
    },
    "gpt-3.5-turbo": {
        "input_cost_per_1k": 0.0015,
        "output_cost_per_1k": 0.002
    },
    "qwen-plus": {
        "input_cost_per_1k": 0.004,
        "output_cost_per_1k": 0.012
    }
}

class UsageTracker:
    """ä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬è·Ÿè¸ªå™¨"""
    
    def __init__(self, redis_client: Optional[redis.Redis] = None):
        self.redis = redis_client
    
    async def track_usage(self, user_id: str, model: str, task_type: str, 
                         usage: Dict[str, int], duration: float):
        """
        è®°å½•ä½¿ç”¨æƒ…å†µ
        
        Args:
            user_id: ç”¨æˆ·ID
            model: æ¨¡å‹åç§°
            task_type: ä»»åŠ¡ç±»å‹
            usage: ä½¿ç”¨ç»Ÿè®¡ {prompt_tokens, completion_tokens, total_tokens}
            duration: è¯·æ±‚è€—æ—¶(ç§’)
        """
        try:
            timestamp = datetime.now()
            
            # è®¡ç®—æˆæœ¬
            cost = self._calculate_cost(model, usage)
            
            # æ„å»ºä½¿ç”¨è®°å½•
            usage_record = {
                "user_id": user_id,
                "model": model,
                "task_type": task_type,
                "timestamp": timestamp.isoformat(),
                "usage": usage,
                "cost": cost,
                "duration": duration
            }
            
            # è®°å½•åˆ°Redis (å¦‚æœå¯ç”¨)
            if self.redis:
                await self._save_to_redis(usage_record)
            
            # è®°å½•åˆ°æ—¥å¿—
            logger.info(f"ğŸ“Š ä½¿ç”¨è®°å½•: {user_id} | {model} | {task_type} | "
                       f"tokens: {usage.get('total_tokens', 0)} | "
                       f"cost: ${cost:.6f} | duration: {duration:.2f}s")
            
        except Exception as e:
            logger.error(f"âŒ è®°å½•ä½¿ç”¨ç»Ÿè®¡å¤±è´¥: {e}")
    
    def _calculate_cost(self, model: str, usage: Dict[str, int]) -> float:
        """è®¡ç®—ä½¿ç”¨æˆæœ¬"""
        pricing = MODEL_PRICING.get(model, {})
        
        if not pricing:
            logger.warning(f"âš ï¸ æ¨¡å‹ {model} æ²¡æœ‰å®šä»·ä¿¡æ¯")
            return 0.0
        
        input_tokens = usage.get("prompt_tokens", 0)
        output_tokens = usage.get("completion_tokens", 0)
        
        input_cost = input_tokens * pricing.get("input_cost_per_1k", 0) / 1000
        output_cost = output_tokens * pricing.get("output_cost_per_1k", 0) / 1000
        
        return input_cost + output_cost
    
    async def _save_to_redis(self, usage_record: Dict[str, Any]):
        """ä¿å­˜åˆ°Redis"""
        try:
            # ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºé”®çš„ä¸€éƒ¨åˆ†ï¼Œä¾¿äºæŒ‰æ—¶é—´æŸ¥è¯¢
            timestamp = datetime.fromisoformat(usage_record["timestamp"])
            date_key = timestamp.strftime("%Y-%m-%d")
            hour_key = timestamp.strftime("%Y-%m-%d:%H")
            
            # ä¿å­˜è¯¦ç»†è®°å½•
            record_key = f"llm:usage:detail:{timestamp.isoformat()}"
            await self.redis.setex(record_key, 86400 * 7, json.dumps(usage_record))  # ä¿å­˜7å¤©
            
            # æ›´æ–°æ—¥ç»Ÿè®¡
            daily_key = f"llm:usage:daily:{date_key}"
            await self._update_aggregated_stats(daily_key, usage_record, 86400 * 30)  # ä¿å­˜30å¤©
            
            # æ›´æ–°å°æ—¶ç»Ÿè®¡
            hourly_key = f"llm:usage:hourly:{hour_key}"
            await self._update_aggregated_stats(hourly_key, usage_record, 86400 * 7)  # ä¿å­˜7å¤©
            
            # æ›´æ–°ç”¨æˆ·ç»Ÿè®¡
            user_key = f"llm:usage:user:{usage_record['user_id']}:{date_key}"
            await self._update_aggregated_stats(user_key, usage_record, 86400 * 30)  # ä¿å­˜30å¤©
            
            # æ›´æ–°æ¨¡å‹ç»Ÿè®¡
            model_key = f"llm:usage:model:{usage_record['model']}:{date_key}"
            await self._update_aggregated_stats(model_key, usage_record, 86400 * 30)  # ä¿å­˜30å¤©
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜åˆ°Rediså¤±è´¥: {e}")
    
    async def _update_aggregated_stats(self, key: str, usage_record: Dict[str, Any], ttl: int):
        """æ›´æ–°èšåˆç»Ÿè®¡"""
        try:
            # è·å–ç°æœ‰ç»Ÿè®¡
            existing_data = await self.redis.get(key)
            if existing_data:
                stats = json.loads(existing_data)
            else:
                stats = {
                    "total_requests": 0,
                    "total_tokens": 0,
                    "total_cost": 0.0,
                    "total_duration": 0.0,
                    "models": {},
                    "task_types": {}
                }
            
            # æ›´æ–°ç»Ÿè®¡
            usage = usage_record["usage"]
            stats["total_requests"] += 1
            stats["total_tokens"] += usage.get("total_tokens", 0)
            stats["total_cost"] += usage_record["cost"]
            stats["total_duration"] += usage_record["duration"]
            
            # æ›´æ–°æ¨¡å‹ç»Ÿè®¡
            model = usage_record["model"]
            if model not in stats["models"]:
                stats["models"][model] = {"requests": 0, "tokens": 0, "cost": 0.0}
            stats["models"][model]["requests"] += 1
            stats["models"][model]["tokens"] += usage.get("total_tokens", 0)
            stats["models"][model]["cost"] += usage_record["cost"]
            
            # æ›´æ–°ä»»åŠ¡ç±»å‹ç»Ÿè®¡
            task_type = usage_record["task_type"]
            if task_type not in stats["task_types"]:
                stats["task_types"][task_type] = {"requests": 0, "tokens": 0, "cost": 0.0}
            stats["task_types"][task_type]["requests"] += 1
            stats["task_types"][task_type]["tokens"] += usage.get("total_tokens", 0)
            stats["task_types"][task_type]["cost"] += usage_record["cost"]
            
            # ä¿å­˜æ›´æ–°åçš„ç»Ÿè®¡
            await self.redis.setex(key, ttl, json.dumps(stats))
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°èšåˆç»Ÿè®¡å¤±è´¥: {e}")
    
    async def get_usage_stats(self, user_id: Optional[str] = None, 
                             model: Optional[str] = None, days: int = 7) -> Dict[str, Any]:
        """
        è·å–ä½¿ç”¨ç»Ÿè®¡
        
        Args:
            user_id: ç”¨æˆ·ID (å¯é€‰)
            model: æ¨¡å‹åç§° (å¯é€‰)
            days: ç»Ÿè®¡å¤©æ•°
            
        Returns:
            ç»Ÿè®¡æ•°æ®
        """
        if not self.redis:
            return {"error": "Redis not available"}
        
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            stats = {
                "period": {
                    "start_date": start_date.strftime("%Y-%m-%d"),
                    "end_date": end_date.strftime("%Y-%m-%d"),
                    "days": days
                },
                "total": {
                    "requests": 0,
                    "tokens": 0,
                    "cost": 0.0,
                    "duration": 0.0
                },
                "daily": [],
                "models": {},
                "task_types": {}
            }
            
            # æŒ‰å¤©ç»Ÿè®¡
            current_date = start_date
            while current_date <= end_date:
                date_str = current_date.strftime("%Y-%m-%d")
                
                # æ„å»ºæŸ¥è¯¢é”®
                if user_id:
                    key = f"llm:usage:user:{user_id}:{date_str}"
                elif model:
                    key = f"llm:usage:model:{model}:{date_str}"
                else:
                    key = f"llm:usage:daily:{date_str}"
                
                # è·å–å½“å¤©ç»Ÿè®¡
                daily_data = await self.redis.get(key)
                if daily_data:
                    daily_stats = json.loads(daily_data)
                    
                    # ç´¯åŠ æ€»è®¡
                    stats["total"]["requests"] += daily_stats.get("total_requests", 0)
                    stats["total"]["tokens"] += daily_stats.get("total_tokens", 0)
                    stats["total"]["cost"] += daily_stats.get("total_cost", 0.0)
                    stats["total"]["duration"] += daily_stats.get("total_duration", 0.0)
                    
                    # æ·»åŠ æ¯æ—¥æ•°æ®
                    stats["daily"].append({
                        "date": date_str,
                        "requests": daily_stats.get("total_requests", 0),
                        "tokens": daily_stats.get("total_tokens", 0),
                        "cost": daily_stats.get("total_cost", 0.0),
                        "duration": daily_stats.get("total_duration", 0.0)
                    })
                    
                    # åˆå¹¶æ¨¡å‹ç»Ÿè®¡
                    for model_name, model_stats in daily_stats.get("models", {}).items():
                        if model_name not in stats["models"]:
                            stats["models"][model_name] = {"requests": 0, "tokens": 0, "cost": 0.0}
                        stats["models"][model_name]["requests"] += model_stats.get("requests", 0)
                        stats["models"][model_name]["tokens"] += model_stats.get("tokens", 0)
                        stats["models"][model_name]["cost"] += model_stats.get("cost", 0.0)
                    
                    # åˆå¹¶ä»»åŠ¡ç±»å‹ç»Ÿè®¡
                    for task_type, task_stats in daily_stats.get("task_types", {}).items():
                        if task_type not in stats["task_types"]:
                            stats["task_types"][task_type] = {"requests": 0, "tokens": 0, "cost": 0.0}
                        stats["task_types"][task_type]["requests"] += task_stats.get("requests", 0)
                        stats["task_types"][task_type]["tokens"] += task_stats.get("tokens", 0)
                        stats["task_types"][task_type]["cost"] += task_stats.get("cost", 0.0)
                
                current_date += timedelta(days=1)
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ è·å–ä½¿ç”¨ç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}
