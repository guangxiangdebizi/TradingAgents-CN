"""
Data Service - æ•°æ®æœåŠ¡
æä¾›è‚¡ç¥¨æ•°æ®è·å–å’Œç¼“å­˜åŠŸèƒ½
"""
import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡ - ä¼˜å…ˆåŠ è½½backendç›®å½•çš„.envï¼Œç„¶åæ˜¯é¡¹ç›®æ ¹ç›®å½•çš„.env
try:
    from dotenv import load_dotenv

    # è·å–backendç›®å½•è·¯å¾„
    backend_dir = Path(__file__).parent.parent.parent

    # ä¼˜å…ˆåŠ è½½backendç›®å½•çš„.envæ–‡ä»¶
    backend_env = backend_dir / ".env"
    if backend_env.exists():
        load_dotenv(backend_env, override=True)
        print(f"âœ… åŠ è½½Backendç¯å¢ƒå˜é‡: {backend_env}")

    # ç„¶ååŠ è½½é¡¹ç›®æ ¹ç›®å½•çš„.envæ–‡ä»¶ï¼ˆä½œä¸ºå¤‡ç”¨ï¼‰
    root_env = project_root / ".env"
    if root_env.exists():
        load_dotenv(root_env, override=False)  # ä¸è¦†ç›–å·²æœ‰çš„ç¯å¢ƒå˜é‡
        print(f"âœ… åŠ è½½é¡¹ç›®æ ¹ç›®å½•ç¯å¢ƒå˜é‡: {root_env}")

    if not backend_env.exists() and not root_env.exists():
        print("âš ï¸ æœªæ‰¾åˆ°.envæ–‡ä»¶ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡")

except ImportError:
    print("âš ï¸ python-dotenvæœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡")

from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import redis.asyncio as redis
from typing import Optional, List

# å¯¼å…¥å…±äº«æ¨¡å—
from backend.shared.models.data import (
    StockDataRequest, StockInfo, StockPrice, MarketData,
    NewsItem, FundamentalData, DataSourceStatus
)
from backend.shared.models.analysis import APIResponse, HealthCheck
from backend.shared.utils.logger import get_service_logger
from backend.shared.utils.config import get_service_config

# å¯¼å…¥å›½é™…åŒ–æ¨¡å—
from backend.shared.i18n import get_i18n_manager, _, SupportedLanguage
from backend.shared.i18n.middleware import I18nMiddleware, i18n_response
from backend.shared.i18n.utils import localize_stock_data, get_supported_languages
from backend.shared.i18n.logger import get_i18n_logger
from backend.shared.i18n.debug_middleware import (
    APIDebugMiddleware, PerformanceMonitorMiddleware, ValidationDebugMiddleware
)

# å¯¼å…¥ç°æœ‰çš„æ•°æ®è·å–é€»è¾‘
from tradingagents.dataflows.interface import (
    get_china_stock_data_unified,
    get_china_stock_info_unified,
    get_china_stock_fundamentals_tushare,
    get_finnhub_news,
    get_hk_stock_data_unified,
    get_hk_stock_info_unified,
    get_stock_data_by_market
)

# å¯¼å…¥æ•°æ®åº“è®¿é—®å±‚
from backend.shared.database.mongodb import get_db_manager, get_stock_repository


def _parse_stock_data_to_structured_format(stock_data: str, symbol: str, start_date: str, end_date: str) -> dict:
    """
    è§£æè‚¡ç¥¨æ•°æ®å­—ç¬¦ä¸²ä¸ºç»“æ„åŒ–æ ¼å¼
    æ”¯æŒMarkdownæ ¼å¼å’Œè¡¨æ ¼æ•°æ®çš„æ··åˆæ ¼å¼

    Args:
        stock_data: æ ¼å¼åŒ–çš„è‚¡ç¥¨æ•°æ®å­—ç¬¦ä¸²
        symbol: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ

    Returns:
        dict: ç»“æ„åŒ–çš„è‚¡ç¥¨æ•°æ®
    """
    try:
        # åˆå§‹åŒ–ç»“æœç»“æ„
        result = {
            "symbol": symbol,
            "start_date": start_date,
            "end_date": end_date,
            "close_prices": [],
            "volumes": [],
            "open_prices": [],
            "high_prices": [],
            "low_prices": [],
            "dates": [],
            "raw_data": stock_data
        }

        lines = stock_data.strip().split('\n')

        # æŸ¥æ‰¾æ•°æ®è¡¨æ ¼éƒ¨åˆ†ï¼ˆé€šå¸¸åœ¨"æœ€æ–°äº¤æ˜“æ•°æ®"æˆ–"æœ€æ–°æ•°æ®"ä¹‹åï¼‰
        data_start_index = -1

        # æ–¹æ³•1ï¼šæŸ¥æ‰¾åŒ…å«è¡¨æ ¼å¤´éƒ¨çš„è¡Œ
        for i, line in enumerate(lines):
            # æŸ¥æ‰¾åŒ…å«åˆ—åçš„è¡Œï¼ˆTushareæ ¼å¼ï¼‰
            if ('ts_code' in line and 'trade_date' in line) or \
               ('ä»£ç ' in line and 'æ—¥æœŸ' in line) or \
               ('open' in line and 'high' in line and 'low' in line and 'close' in line):
                data_start_index = i
                print(f"ğŸ” æ‰¾åˆ°è¡¨æ ¼å¤´éƒ¨: {line}")
                break

        # æ–¹æ³•2ï¼šå¦‚æœæ²¡æ‰¾åˆ°æ ‡å‡†å¤´éƒ¨ï¼ŒæŸ¥æ‰¾æ•°æ®è¡Œæ¨¡å¼
        if data_start_index == -1:
            for i, line in enumerate(lines):
                # æŸ¥æ‰¾åŒ…å«è‚¡ç¥¨ä»£ç å’Œæ•°å­—çš„è¡Œï¼ˆæ•°æ®è¡Œç‰¹å¾ï¼‰
                if symbol in line and any(char.isdigit() for char in line):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯è¡¨æ ¼æ•°æ®è¡Œæ ¼å¼
                    parts = line.split()
                    if len(parts) >= 6:  # è‡³å°‘åŒ…å«ä»£ç ã€æ—¥æœŸã€å¼€ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜
                        data_start_index = i
                        print(f"ğŸ” æ‰¾åˆ°æ•°æ®è¡Œå¼€å§‹: {line}")
                        break

        if data_start_index == -1:
            print(f"âš ï¸ æ— æ³•æ‰¾åˆ°æ•°æ®è¡¨æ ¼: {symbol}")
            return result

        # è§£ææ•°æ®è¡Œ
        for line in lines[data_start_index:]:
            if not line.strip() or line.startswith('#') or line.startswith('##'):
                continue

            # è·³è¿‡è¡¨æ ¼å¤´éƒ¨è¡Œ
            if 'ts_code' in line or 'trade_date' in line or 'ä»£ç ' in line or 'æ—¥æœŸ' in line:
                continue

            # è§£ææ•°æ®è¡Œï¼ˆæ”¯æŒç©ºæ ¼åˆ†éš”å’Œé€—å·åˆ†éš”ï¼‰
            parts = line.split() if ' ' in line else line.split(',')

            if len(parts) >= 6:  # è‡³å°‘åŒ…å«ä»£ç ã€æ—¥æœŸã€å¼€ç›˜ã€æœ€é«˜ã€æœ€ä½ã€æ”¶ç›˜
                try:
                    # Tushareæ ¼å¼: ts_code trade_date open high low close pre_close change pct_chg vol amount
                    if len(parts) >= 10:  # å®Œæ•´çš„Tushareæ ¼å¼
                        ts_code = parts[0].strip()
                        trade_date = parts[1].strip()
                        open_price = float(parts[2].strip()) if parts[2].strip() and parts[2].strip() != 'NaN' else 0.0
                        high_price = float(parts[3].strip()) if parts[3].strip() and parts[3].strip() != 'NaN' else 0.0
                        low_price = float(parts[4].strip()) if parts[4].strip() and parts[4].strip() != 'NaN' else 0.0
                        close_price = float(parts[5].strip()) if parts[5].strip() and parts[5].strip() != 'NaN' else 0.0
                        volume = int(float(parts[9].strip())) if parts[9].strip() and parts[9].strip() != 'NaN' else 0

                        result["dates"].append(trade_date)
                        result["open_prices"].append(open_price)
                        result["high_prices"].append(high_price)
                        result["low_prices"].append(low_price)
                        result["close_prices"].append(close_price)
                        result["volumes"].append(volume)

                    else:  # ç®€åŒ–æ ¼å¼
                        date = parts[1].strip() if len(parts) > 1 else parts[0].strip()
                        open_price = float(parts[2].strip()) if len(parts) > 2 and parts[2].strip() and parts[2].strip() != 'NaN' else 0.0
                        high_price = float(parts[3].strip()) if len(parts) > 3 and parts[3].strip() and parts[3].strip() != 'NaN' else 0.0
                        low_price = float(parts[4].strip()) if len(parts) > 4 and parts[4].strip() and parts[4].strip() != 'NaN' else 0.0
                        close_price = float(parts[5].strip()) if len(parts) > 5 and parts[5].strip() and parts[5].strip() != 'NaN' else 0.0
                        volume = int(float(parts[6].strip())) if len(parts) > 6 and parts[6].strip() and parts[6].strip() != 'NaN' else 0

                        result["dates"].append(date)
                        result["open_prices"].append(open_price)
                        result["high_prices"].append(high_price)
                        result["low_prices"].append(low_price)
                        result["close_prices"].append(close_price)
                        result["volumes"].append(volume)

                except (ValueError, IndexError) as e:
                    print(f"âš ï¸ è§£ææ•°æ®è¡Œå¤±è´¥: {line} - {e}")
                    continue

        print(f"âœ… è§£æè‚¡ç¥¨æ•°æ®æˆåŠŸ: {symbol}, å…±{len(result['close_prices'])}æ¡è®°å½•")
        return result

    except Exception as e:
        print(f"âŒ è§£æè‚¡ç¥¨æ•°æ®å¤±è´¥: {symbol} - {e}")
        import traceback
        print(f"âŒ è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return {
            "symbol": symbol,
            "start_date": start_date,
            "end_date": end_date,
            "close_prices": [],
            "volumes": [],
            "open_prices": [],
            "high_prices": [],
            "low_prices": [],
            "dates": [],
            "raw_data": stock_data,
            "error": str(e)
        }


# å…¨å±€å˜é‡
logger = get_service_logger("data-service")
debug_logger = get_i18n_logger("data-service-debug")
redis_client: Optional[redis.Redis] = None
db_manager = None
data_manager_instance = None
enhanced_data_manager_instance = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global redis_client, db_manager

    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    logger.info("ğŸš€ Data Service å¯åŠ¨ä¸­...")

    # åˆå§‹åŒ–Redisè¿æ¥
    config = get_service_config("data_service")
    try:
        redis_client = redis.from_url(config['redis_url'])
        await redis_client.ping()
        logger.info("âœ… Redis è¿æ¥æˆåŠŸ")
    except Exception as e:
        logger.warning(f"âš ï¸ Redis è¿æ¥å¤±è´¥: {e}")
        redis_client = None

    # åˆå§‹åŒ–MongoDBè¿æ¥
    try:
        db_manager = await get_db_manager()
        if db_manager.is_connected():
            logger.info("âœ… MongoDB è¿æ¥æˆåŠŸ")
        else:
            logger.warning("âš ï¸ MongoDB è¿æ¥å¤±è´¥")
    except Exception as e:
        logger.warning(f"âš ï¸ MongoDB åˆå§‹åŒ–å¤±è´¥: {e}")
        db_manager = None

    logger.info("âœ… Data Service å¯åŠ¨å®Œæˆ")

    yield

    # å…³é—­æ—¶æ¸…ç†
    logger.info("ğŸ›‘ Data Service å…³é—­ä¸­...")
    if redis_client:
        await redis_client.close()
    if db_manager:
        await db_manager.disconnect()
    logger.info("âœ… Data Service å·²å…³é—­")


def get_data_manager():
    """è·å–æ•°æ®ç®¡ç†å™¨å®ä¾‹"""
    global data_manager_instance
    if data_manager_instance is None:
        # å¯¼å…¥å¹¶åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨
        try:
            from .data_manager import DataManager
            from pymongo import MongoClient
            import redis

            # åˆ›å»ºæ•°æ®åº“è¿æ¥ (å¸¦è®¤è¯)
            mongodb_client = MongoClient("mongodb://admin:tradingagents123@localhost:27017/tradingagents?authSource=admin")
            redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)

            # è·å–å½“å‰è¯­è¨€è®¾ç½®
            current_language = get_i18n_manager().get_language()

            # åˆ›å»ºæ•°æ®ç®¡ç†å™¨å®ä¾‹
            data_manager_instance = DataManager(mongodb_client, redis_client, current_language)
            logger.info("âœ… æ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ æ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"æ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")

    return data_manager_instance


def get_enhanced_data_manager():
    """è·å–å¢å¼ºæ•°æ®ç®¡ç†å™¨å®ä¾‹"""
    global enhanced_data_manager_instance
    if enhanced_data_manager_instance is None:
        try:
            from .enhanced_data_manager import EnhancedDataManager
            from pymongo import MongoClient
            import redis

            # åˆ›å»ºæ•°æ®åº“è¿æ¥ (å¸¦è®¤è¯)
            mongodb_client = MongoClient("mongodb://admin:tradingagents123@localhost:27017/tradingagents?authSource=admin")
            redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)

            # è·å–å½“å‰è¯­è¨€è®¾ç½®
            current_language = get_i18n_manager().get_language()

            # åˆ›å»ºå¢å¼ºæ•°æ®ç®¡ç†å™¨å®ä¾‹
            enhanced_data_manager_instance = EnhancedDataManager(mongodb_client, redis_client, current_language)
            logger.info("âœ… å¢å¼ºæ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ å¢å¼ºæ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"å¢å¼ºæ•°æ®ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")

    return enhanced_data_manager_instance


# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="TradingAgents Data Service",
    description="è‚¡ç¥¨æ•°æ®è·å–å’Œç¼“å­˜æœåŠ¡",
    version="1.0.0",
    lifespan=lifespan
)

# è®¾ç½®é»˜è®¤å“åº”ç±»ï¼Œç¡®ä¿ä¸­æ–‡ç¼–ç æ­£ç¡®
from fastapi.responses import JSONResponse
from fastapi.encoders import jsonable_encoder
import json

class UTF8JSONResponse(JSONResponse):
    def render(self, content) -> bytes:
        return json.dumps(
            jsonable_encoder(content),
            ensure_ascii=False,
            allow_nan=False,
            indent=None,
            separators=(",", ":"),
        ).encode("utf-8")

app.default_response_class = UTF8JSONResponse

# æ·»åŠ è°ƒè¯•ä¸­é—´ä»¶ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
import os
DEBUG_MODE = os.getenv("DEBUG", "false").lower() == "true"

if DEBUG_MODE:
    # APIè°ƒè¯•ä¸­é—´ä»¶
    app.add_middleware(
        APIDebugMiddleware,
        enable_debug=True,
        log_headers=True,
        log_body=True
    )

    # æ€§èƒ½ç›‘æ§ä¸­é—´ä»¶
    app.add_middleware(PerformanceMonitorMiddleware, enable_monitoring=True)

    # éªŒè¯è°ƒè¯•ä¸­é—´ä»¶
    app.add_middleware(ValidationDebugMiddleware, enable_validation_debug=True)

# æ·»åŠ å›½é™…åŒ–ä¸­é—´ä»¶
app.add_middleware(I18nMiddleware, auto_detect=True)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


async def get_redis() -> Optional[redis.Redis]:
    """è·å–Rediså®¢æˆ·ç«¯"""
    return redis_client


@app.get("/health", response_model=HealthCheck)
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    dependencies = {}
    
    # æ£€æŸ¥Redisè¿æ¥
    if redis_client:
        try:
            await redis_client.ping()
            dependencies["redis"] = "healthy"
        except Exception:
            dependencies["redis"] = "unhealthy"
    else:
        dependencies["redis"] = "not_configured"
    
    return HealthCheck(
        service_name="data-service",
        status="healthy",
        version="1.0.0",
        dependencies=dependencies
    )

# ===== å›½é™…åŒ–æ¥å£ =====

@app.get("/api/i18n/languages", response_model=APIResponse)
async def get_supported_languages_api():
    """è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨"""
    try:
        languages = get_supported_languages()
        return i18n_response.success_response("api.success.languages", languages)
    except Exception as e:
        logger.error(f"âŒ è·å–è¯­è¨€åˆ—è¡¨å¤±è´¥: {e}")
        return i18n_response.error_response("api.error.internal_error")

@app.get("/api/i18n/current", response_model=APIResponse)
async def get_current_language():
    """è·å–å½“å‰è¯­è¨€"""
    try:
        i18n_manager = get_i18n_manager()
        current_lang = i18n_manager.get_language()

        return i18n_response.success_response("api.success.current_language", {
            "language": current_lang.value,
            "name": i18n_manager.get_available_languages().get(current_lang.value, current_lang.value)
        })
    except Exception as e:
        logger.error(f"âŒ è·å–å½“å‰è¯­è¨€å¤±è´¥: {e}")
        return i18n_response.error_response("api.error.internal_error")

@app.post("/api/i18n/set-language", response_model=APIResponse)
async def set_language(request: dict):
    """è®¾ç½®è¯­è¨€"""
    try:
        language = request.get("language")
        if not language:
            return i18n_response.error_response("api.validation.required_field")

        i18n_manager = get_i18n_manager()
        if i18n_manager.set_language(language):
            return i18n_response.success_response("api.success.language_set", {
                "language": i18n_manager.get_language().value
            })
        else:
            return i18n_response.error_response("api.error.invalid_language")
    except Exception as e:
        logger.error(f"âŒ è®¾ç½®è¯­è¨€å¤±è´¥: {e}")
        return i18n_response.error_response("api.error.internal_error")

@app.get("/api/i18n/stats", response_model=APIResponse)
async def get_translation_stats():
    """è·å–ç¿»è¯‘ç»Ÿè®¡ä¿¡æ¯"""
    try:
        i18n_manager = get_i18n_manager()
        stats = i18n_manager.get_translation_stats()
        return i18n_response.success_response("api.success.translation_stats", stats)
    except Exception as e:
        logger.error(f"âŒ è·å–ç¿»è¯‘ç»Ÿè®¡å¤±è´¥: {e}")
        return i18n_response.error_response("api.error.internal_error")

@app.post("/api/i18n/set-log-language", response_model=APIResponse)
async def set_log_language(request: dict):
    """è®¾ç½®æ—¥å¿—è¯­è¨€"""
    try:
        language = request.get("language")
        if not language:
            return i18n_response.error_response("api.validation.required_field")

        # è®¾ç½®å…¨å±€è¯­è¨€
        i18n_manager = get_i18n_manager()
        if not i18n_manager.set_language(language):
            return i18n_response.error_response("api.error.invalid_language")

        # è®¾ç½®æ•°æ®ç®¡ç†å™¨æ—¥å¿—è¯­è¨€
        data_manager = get_data_manager()
        data_manager.set_log_language(i18n_manager.get_language())

        return i18n_response.success_response("api.success.log_language_set", {
            "language": i18n_manager.get_language().value
        })
    except Exception as e:
        logger.error(f"âŒ è®¾ç½®æ—¥å¿—è¯­è¨€å¤±è´¥: {e}")
        return i18n_response.error_response("api.error.internal_error")

@app.get("/api/stock/info/{symbol}", response_model=APIResponse)
async def get_stock_info(
    symbol: str,
    force_refresh: bool = False,  # æ·»åŠ å¼ºåˆ¶åˆ·æ–°å‚æ•°
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯"""
    try:
        # Debug: è®°å½•APIè°ƒç”¨å¼€å§‹
        debug_logger.debug_api_request_received("GET", f"/api/stock/info/{symbol}")
        debug_logger.debug_validation_start("symbol")

        if not symbol or len(symbol.strip()) == 0:
            debug_logger.debug_validation_failed("symbol", "empty_or_invalid")
            raise HTTPException(status_code=400, detail="è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º")

        debug_logger.debug_validation_passed("symbol")
        logger.info(f"ğŸ“Š è·å–è‚¡ç¥¨ä¿¡æ¯: {symbol}")

        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"stock_info:{symbol}"
        debug_logger.debug_cache_check_start(symbol, "stock_info")

        # æ£€æŸ¥ç¼“å­˜ï¼ˆé™¤éå¼ºåˆ¶åˆ·æ–°ï¼‰
        if redis_client and not force_refresh:
            cached_data = await redis_client.get(cache_key)
            if cached_data:
                debug_logger.debug_cache_check_result("hit", symbol)
                logger.debug(f"ğŸ’¾ ä»ç¼“å­˜è·å–è‚¡ç¥¨ä¿¡æ¯: {symbol}")
                import json

                debug_logger.debug_api_response_prepared(200)
                return APIResponse(
                    success=True,
                    message="è·å–è‚¡ç¥¨ä¿¡æ¯æˆåŠŸï¼ˆç¼“å­˜ï¼‰",
                    data=json.loads(cached_data)
                )

        if force_refresh:
            logger.info(f"ğŸ”„ å¼ºåˆ¶åˆ·æ–°è‚¡ç¥¨ä¿¡æ¯: {symbol}")

        debug_logger.debug_cache_check_result("miss", symbol)
        
        # ä»æ•°æ®æºè·å–
        debug_logger.debug_data_source_select("china_stock_unified", symbol)
        debug_logger.debug_data_source_call("china_stock_unified", f"stock_info/{symbol}")

        info_data = get_china_stock_info_unified(symbol)

        if not info_data or "é”™è¯¯" in str(info_data):
            debug_logger.debug_data_source_response("china_stock_unified", "error", 0)
            raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°è‚¡ç¥¨ {symbol} çš„ä¿¡æ¯")

        debug_logger.debug_data_source_response("china_stock_unified", "success", len(str(info_data)))

        # è§£ææ•°æ®ï¼ˆä»Tushareè¿”å›çš„æ•°æ®ä¸­æå–ï¼‰
        debug_logger.debug_data_transform_start("raw_response", "stock_info")

        # è°ƒè¯•ï¼šæ‰“å°info_dataçš„ç±»å‹å’Œå†…å®¹
        logger.info(f"ğŸ” [è°ƒè¯•] info_dataç±»å‹: {type(info_data)}")
        logger.info(f"ğŸ” [è°ƒè¯•] info_dataå†…å®¹: {info_data}")

        # ä»info_dataä¸­æå–å®é™…æ•°æ®
        if isinstance(info_data, str) and "è‚¡ç¥¨åç§°:" in info_data:
            # è§£æå­—ç¬¦ä¸²æ ¼å¼çš„æ•°æ®
            lines = info_data.split('\n')
            name = "æœªçŸ¥è‚¡ç¥¨"
            area = None
            industry = None
            market = "Aè‚¡"

            for line in lines:
                if "è‚¡ç¥¨åç§°:" in line:
                    name = line.split(':')[1].strip()
                elif "æ‰€å±åœ°åŒº:" in line:
                    area = line.split(':')[1].strip()
                elif "æ‰€å±è¡Œä¸š:" in line:
                    industry = line.split(':')[1].strip()
                elif "ä¸Šå¸‚å¸‚åœº:" in line:
                    market = line.split(':')[1].strip()

            stock_info = {
                "symbol": symbol,
                "name": name,
                "market": market,
                "industry": industry,
                "sector": area,
                "market_cap": None,
                "currency": "CNY"
            }
        elif isinstance(info_data, list) and len(info_data) > 0:
            # å¤„ç†åˆ—è¡¨æ ¼å¼çš„æ•°æ®
            data = info_data[0]  # å–ç¬¬ä¸€æ¡è®°å½•
            stock_info = {
                "symbol": symbol,
                "name": data.get("name", "æœªçŸ¥è‚¡ç¥¨"),
                "market": data.get("market", "Aè‚¡"),
                "industry": data.get("industry"),
                "sector": data.get("area"),  # ä½¿ç”¨areaä½œä¸ºsector
                "market_cap": None,  # TushareåŸºç¡€ä¿¡æ¯ä¸­æ²¡æœ‰å¸‚å€¼
                "currency": "CNY"
            }
        else:
            # å¦‚æœæ•°æ®æ ¼å¼ä¸å¯¹ï¼Œä½¿ç”¨é»˜è®¤å€¼
            stock_info = {
                "symbol": symbol,
                "name": "æœªçŸ¥è‚¡ç¥¨",
                "market": "Aè‚¡",
                "industry": None,
                "sector": None,
                "market_cap": None,
                "currency": "CNY"
            }
        debug_logger.debug_data_transform_end(1)

        # è¯¦ç»†è°ƒè¯•ï¼šæ‰“å°æœ€ç»ˆçš„stock_infoå†…å®¹
        logger.info(f"ğŸ” [æœ€ç»ˆç»“æœ] stock_infoå†…å®¹: {stock_info}")

        # ç¼“å­˜æ•°æ®
        if redis_client:
            debug_logger.debug_cache_save_start(symbol, "stock_info")
            import json
            await redis_client.setex(
                cache_key,
                3600,  # 1å°æ—¶ç¼“å­˜
                json.dumps(stock_info, ensure_ascii=False)
            )
            debug_logger.debug_cache_save_end(symbol, 3600)

        # æœ¬åœ°åŒ–æ•°æ®
        debug_logger.debug_data_transform_start("stock_info", "localized_data")
        localized_data = localize_stock_data(stock_info)
        debug_logger.debug_data_transform_end(1)

        # Debug: è®°å½•å“åº”å‡†å¤‡
        debug_logger.debug_api_response_prepared(200)

        # ä½¿ç”¨å›½é™…åŒ–å“åº”
        return i18n_response.success_response("api.success.stock_info", localized_data)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {str(e)}")


@app.post("/api/stock/data", response_model=APIResponse)
async def get_stock_data(
    request: StockDataRequest,
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """è·å–è‚¡ç¥¨å†å²æ•°æ®"""
    try:
        logger.info(f"ğŸ“ˆ è·å–è‚¡ç¥¨æ•°æ®: {request.symbol} ({request.start_date} - {request.end_date})")
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"stock_data:{request.symbol}:{request.start_date}:{request.end_date}"
        if redis_client:
            cached_data = await redis_client.get(cache_key)
            if cached_data:
                logger.debug(f"ğŸ’¾ ä»ç¼“å­˜è·å–è‚¡ç¥¨æ•°æ®: {request.symbol}")
                import json
                return APIResponse(
                    success=True,
                    message="è·å–è‚¡ç¥¨æ•°æ®æˆåŠŸï¼ˆç¼“å­˜ï¼‰",
                    data=json.loads(cached_data)
                )
        
        # ä»æ•°æ®æºè·å–
        logger.info(f"ğŸ” è°ƒç”¨æ•°æ®æºè·å–: {request.symbol}")
        stock_data = get_china_stock_data_unified(
            request.symbol,
            request.start_date,
            request.end_date
        )

        logger.info(f"ğŸ” åŸå§‹æ•°æ®ç±»å‹: {type(stock_data)}")
        logger.info(f"ğŸ” åŸå§‹æ•°æ®é•¿åº¦: {len(str(stock_data)) if stock_data else 0}")
        logger.info(f"ğŸ” åŸå§‹æ•°æ®å®Œæ•´å†…å®¹: {str(stock_data) if stock_data else 'None'}")

        if not stock_data or "é”™è¯¯" in str(stock_data):
            raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°è‚¡ç¥¨ {request.symbol} çš„æ•°æ®")

        # è§£ææ•°æ®ä¸ºç»“æ„åŒ–æ ¼å¼
        logger.info(f"ğŸ” å¼€å§‹è§£ææ•°æ®ä¸ºç»“æ„åŒ–æ ¼å¼: {request.symbol}")
        parsed_data = _parse_stock_data_to_structured_format(
            stock_data, request.symbol, request.start_date, request.end_date
        )

        logger.info(f"ğŸ” è§£æåæ•°æ®ç±»å‹: {type(parsed_data)}")
        logger.info(f"ğŸ” è§£æåæ•°æ®é”®: {list(parsed_data.keys()) if isinstance(parsed_data, dict) else 'Not a dict'}")
        if isinstance(parsed_data, dict):
            logger.info(f"ğŸ” close_pricesæ•°é‡: {len(parsed_data.get('close_prices', []))}")
            logger.info(f"ğŸ” volumesæ•°é‡: {len(parsed_data.get('volumes', []))}")
        logger.info(f"ğŸ” è§£æåæ•°æ®: {str(parsed_data)[:300]}")
        
        # ç¼“å­˜æ•°æ®
        if redis_client:
            import json
            await redis_client.setex(
                cache_key,
                1800,  # 30åˆ†é’Ÿç¼“å­˜
                json.dumps(parsed_data, ensure_ascii=False)
            )
        
        return APIResponse(
            success=True,
            message="è·å–è‚¡ç¥¨æ•°æ®æˆåŠŸ",
            data=parsed_data
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}")


@app.get("/api/stock/fundamentals/{symbol}", response_model=APIResponse)
async def get_stock_fundamentals(
    symbol: str,
    start_date: str,
    end_date: str,
    curr_date: str,
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """è·å–è‚¡ç¥¨åŸºæœ¬é¢æ•°æ®"""
    try:
        logger.info(f"ğŸ“Š è·å–åŸºæœ¬é¢æ•°æ®: {symbol}")
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"fundamentals:{symbol}:{curr_date}"
        if redis_client:
            cached_data = await redis_client.get(cache_key)
            if cached_data:
                logger.debug(f"ğŸ’¾ ä»ç¼“å­˜è·å–åŸºæœ¬é¢æ•°æ®: {symbol}")
                import json
                return APIResponse(
                    success=True,
                    message="è·å–åŸºæœ¬é¢æ•°æ®æˆåŠŸï¼ˆç¼“å­˜ï¼‰",
                    data=json.loads(cached_data)
                )
        
        # ä»æ•°æ®æºè·å–
        fundamentals_data = get_china_stock_fundamentals_tushare(symbol)
        
        if not fundamentals_data or "é”™è¯¯" in str(fundamentals_data):
            raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°è‚¡ç¥¨ {symbol} çš„åŸºæœ¬é¢æ•°æ®")
        
        result_data = {
            "symbol": symbol,
            "data": fundamentals_data,
            "date": curr_date
        }
        
        # ç¼“å­˜æ•°æ®
        if redis_client:
            import json
            await redis_client.setex(
                cache_key,
                3600,  # 1å°æ—¶ç¼“å­˜
                json.dumps(result_data, ensure_ascii=False)
            )
        
        return APIResponse(
            success=True,
            message="è·å–åŸºæœ¬é¢æ•°æ®æˆåŠŸ",
            data=result_data
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–åŸºæœ¬é¢æ•°æ®å¤±è´¥: {str(e)}")


@app.get("/api/stock/news/{symbol}", response_model=APIResponse)
async def get_stock_news(
    symbol: str,
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """è·å–è‚¡ç¥¨æ–°é—»"""
    try:
        logger.info(f"ğŸ“° è·å–è‚¡ç¥¨æ–°é—»: {symbol}")
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = f"news:{symbol}"
        if redis_client:
            cached_data = await redis_client.get(cache_key)
            if cached_data:
                logger.debug(f"ğŸ’¾ ä»ç¼“å­˜è·å–è‚¡ç¥¨æ–°é—»: {symbol}")
                import json
                return APIResponse(
                    success=True,
                    message="è·å–è‚¡ç¥¨æ–°é—»æˆåŠŸï¼ˆç¼“å­˜ï¼‰",
                    data=json.loads(cached_data)
                )
        
        # ä»æ•°æ®æºè·å– (ä½¿ç”¨å®æ—¶æ–°é—»API)
        try:
            from tradingagents.dataflows.realtime_news_utils import get_realtime_stock_news
            from datetime import datetime
            curr_date = datetime.now().strftime('%Y-%m-%d')
            hours_back = 24 * 7  # æŸ¥çœ‹æœ€è¿‘7å¤©çš„æ–°é—»
            news_data = get_realtime_stock_news(symbol, curr_date, hours_back)
        except ImportError:
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æœ¬åœ°æ–‡ä»¶æ–¹å¼
            from datetime import datetime
            curr_date = datetime.now().strftime('%Y-%m-%d')
            look_back_days = 7
            news_data = get_finnhub_news(symbol, curr_date, look_back_days)
        
        if not news_data or "é”™è¯¯" in str(news_data):
            raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°è‚¡ç¥¨ {symbol} çš„æ–°é—»")
        
        result_data = {
            "symbol": symbol,
            "news": news_data
        }
        
        # ç¼“å­˜æ•°æ®
        if redis_client:
            import json
            await redis_client.setex(
                cache_key,
                1800,  # 30åˆ†é’Ÿç¼“å­˜
                json.dumps(result_data, ensure_ascii=False)
            )
        
        return APIResponse(
            success=True,
            message="è·å–è‚¡ç¥¨æ–°é—»æˆåŠŸ",
            data=result_data
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–è‚¡ç¥¨æ–°é—»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–è‚¡ç¥¨æ–°é—»å¤±è´¥: {str(e)}")


@app.get("/api/data-sources/status", response_model=APIResponse)
async def get_data_sources_status():
    """è·å–æ•°æ®æºçŠ¶æ€"""
    try:
        data_manager = get_data_manager()
        status_data = await data_manager.health_check_data_sources()

        return APIResponse(
            success=True,
            message="è·å–æ•°æ®æºçŠ¶æ€æˆåŠŸ",
            data=status_data
        )

    except Exception as e:
        logger.error(f"âŒ è·å–æ•°æ®æºçŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æ•°æ®æºçŠ¶æ€å¤±è´¥: {str(e)}")

@app.get("/api/data-sources/stats", response_model=APIResponse)
async def get_data_sources_stats():
    """è·å–æ•°æ®æºç»Ÿè®¡ä¿¡æ¯"""
    try:
        data_manager = get_data_manager()
        factory = data_manager.data_source_factory
        stats_data = factory.get_source_stats()

        return APIResponse(
            success=True,
            message="è·å–æ•°æ®æºç»Ÿè®¡æˆåŠŸ",
            data=stats_data
        )

    except Exception as e:
        logger.error(f"âŒ è·å–æ•°æ®æºç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æ•°æ®æºç»Ÿè®¡å¤±è´¥: {str(e)}")

@app.post("/api/data-sources/health-check", response_model=APIResponse)
async def trigger_health_check():
    """æ‰‹åŠ¨è§¦å‘æ•°æ®æºå¥åº·æ£€æŸ¥"""
    try:
        data_manager = get_data_manager()
        health_status = await data_manager.health_check_data_sources()

        return APIResponse(
            success=True,
            message="æ•°æ®æºå¥åº·æ£€æŸ¥å®Œæˆ",
            data=health_status
        )

    except Exception as e:
        logger.error(f"âŒ æ•°æ®æºå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ•°æ®æºå¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")

# ===== æ•°æ®æºä¼˜å…ˆçº§ç®¡ç†æ¥å£ =====

@app.get("/api/data-sources/priority/profiles", response_model=APIResponse)
async def get_priority_profiles():
    """è·å–æ‰€æœ‰ä¼˜å…ˆçº§é…ç½®æ–‡ä»¶"""
    try:
        data_manager = get_data_manager()
        factory = data_manager.data_source_factory
        profiles = factory.get_available_priority_profiles()

        return APIResponse(
            success=True,
            message="è·å–ä¼˜å…ˆçº§é…ç½®æ–‡ä»¶æˆåŠŸ",
            data=profiles
        )

    except Exception as e:
        logger.error(f"âŒ è·å–ä¼˜å…ˆçº§é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ä¼˜å…ˆçº§é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")

@app.get("/api/data-sources/priority/current", response_model=APIResponse)
async def get_current_priority_profile():
    """è·å–å½“å‰ä½¿ç”¨çš„ä¼˜å…ˆçº§é…ç½®æ–‡ä»¶"""
    try:
        data_manager = get_data_manager()
        factory = data_manager.data_source_factory
        current_profile = factory.get_current_priority_profile()

        return APIResponse(
            success=True,
            message="è·å–å½“å‰ä¼˜å…ˆçº§é…ç½®æˆåŠŸ",
            data={"current_profile": current_profile}
        )

    except Exception as e:
        logger.error(f"âŒ è·å–å½“å‰ä¼˜å…ˆçº§é…ç½®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å½“å‰ä¼˜å…ˆçº§é…ç½®å¤±è´¥: {str(e)}")

@app.post("/api/data-sources/priority/switch", response_model=APIResponse)
async def switch_priority_profile(request: dict):
    """åˆ‡æ¢ä¼˜å…ˆçº§é…ç½®æ–‡ä»¶"""
    try:
        profile_name = request.get("profile_name")
        if not profile_name:
            raise HTTPException(status_code=400, detail="ç¼ºå°‘ profile_name å‚æ•°")

        data_manager = get_data_manager()
        factory = data_manager.data_source_factory

        if factory.set_priority_profile(profile_name):
            return APIResponse(
                success=True,
                message=f"æˆåŠŸåˆ‡æ¢åˆ°é…ç½®æ–‡ä»¶: {profile_name}",
                data={"new_profile": profile_name}
            )
        else:
            raise HTTPException(status_code=400, detail=f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {profile_name}")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ åˆ‡æ¢ä¼˜å…ˆçº§é…ç½®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ‡æ¢ä¼˜å…ˆçº§é…ç½®å¤±è´¥: {str(e)}")

@app.post("/api/data-sources/priority/reload", response_model=APIResponse)
async def reload_priority_config():
    """é‡æ–°åŠ è½½ä¼˜å…ˆçº§é…ç½®"""
    try:
        data_manager = get_data_manager()
        factory = data_manager.data_source_factory

        if factory.reload_priority_config():
            return APIResponse(
                success=True,
                message="ä¼˜å…ˆçº§é…ç½®é‡æ–°åŠ è½½æˆåŠŸ",
                data={}
            )
        else:
            raise HTTPException(status_code=500, detail="é‡æ–°åŠ è½½é…ç½®å¤±è´¥")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ é‡æ–°åŠ è½½ä¼˜å…ˆçº§é…ç½®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"é‡æ–°åŠ è½½ä¼˜å…ˆçº§é…ç½®å¤±è´¥: {str(e)}")

# ===== æœ¬åœ°æ•°æ®ç®¡ç†æ¥å£ =====

@app.get("/api/local-data/summary", response_model=APIResponse)
async def get_local_data_summary():
    """è·å–æœ¬åœ°æ•°æ®å­˜å‚¨æ‘˜è¦"""
    try:
        data_manager = get_data_manager()
        summary = await data_manager.get_local_data_summary()

        return APIResponse(
            success=True,
            message="è·å–æœ¬åœ°æ•°æ®æ‘˜è¦æˆåŠŸ",
            data=summary
        )

    except Exception as e:
        logger.error(f"âŒ è·å–æœ¬åœ°æ•°æ®æ‘˜è¦å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æœ¬åœ°æ•°æ®æ‘˜è¦å¤±è´¥: {str(e)}")

@app.get("/api/local-data/history/{symbol}", response_model=APIResponse)
async def get_symbol_data_history(symbol: str):
    """è·å–ç‰¹å®šè‚¡ç¥¨çš„æ•°æ®å†å²"""
    try:
        data_manager = get_data_manager()
        history = await data_manager.get_symbol_data_history(symbol)

        return APIResponse(
            success=True,
            message=f"è·å– {symbol} æ•°æ®å†å²æˆåŠŸ",
            data=history
        )

    except Exception as e:
        logger.error(f"âŒ è·å–è‚¡ç¥¨æ•°æ®å†å²å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–è‚¡ç¥¨æ•°æ®å†å²å¤±è´¥: {str(e)}")

@app.post("/api/local-data/cleanup", response_model=APIResponse)
async def cleanup_old_data(request: dict):
    """æ¸…ç†æ—§æ•°æ®"""
    try:
        days = request.get("days", 30)
        if not isinstance(days, int) or days < 1:
            raise HTTPException(status_code=400, detail="days å‚æ•°å¿…é¡»æ˜¯å¤§äº0çš„æ•´æ•°")

        data_manager = get_data_manager()
        cleanup_stats = await data_manager.cleanup_old_data(days)

        return APIResponse(
            success=True,
            message=f"æ¸…ç† {days} å¤©å‰çš„æ—§æ•°æ®æˆåŠŸ",
            data=cleanup_stats
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†æ—§æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†æ—§æ•°æ®å¤±è´¥: {str(e)}")

@app.post("/api/local-data/force-refresh", response_model=APIResponse)
async def force_refresh_data(request: dict):
    """å¼ºåˆ¶åˆ·æ–°æ•°æ®ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰"""
    try:
        symbol = request.get("symbol")
        data_type = request.get("data_type")

        if not symbol or not data_type:
            raise HTTPException(status_code=400, detail="ç¼ºå°‘ symbol æˆ– data_type å‚æ•°")

        # éªŒè¯æ•°æ®ç±»å‹
        try:
            from .data_manager import DataType
            dt = DataType(data_type)
        except ValueError:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„æ•°æ®ç±»å‹: {data_type}")

        data_manager = get_data_manager()

        # å‡†å¤‡é¢å¤–å‚æ•°
        kwargs = {}
        if dt in [DataType.STOCK_DATA, DataType.FUNDAMENTALS]:
            kwargs["start_date"] = request.get("start_date", "2024-01-01")
            kwargs["end_date"] = request.get("end_date", "2024-12-31")
        elif dt == DataType.NEWS:
            kwargs["start_date"] = request.get("start_date", "2024-01-01")
            kwargs["end_date"] = request.get("end_date", "2024-12-31")

        success, data = await data_manager.force_refresh_data(symbol, dt, **kwargs)

        if success:
            return APIResponse(
                success=True,
                message=f"å¼ºåˆ¶åˆ·æ–° {symbol} {data_type} æ•°æ®æˆåŠŸ",
                data={"symbol": symbol, "data_type": data_type, "refreshed": True}
            )
        else:
            raise HTTPException(status_code=500, detail="æ•°æ®åˆ·æ–°å¤±è´¥")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å¼ºåˆ¶åˆ·æ–°æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¼ºåˆ¶åˆ·æ–°æ•°æ®å¤±è´¥: {str(e)}")


# ===== ä»¥ä¸‹æ˜¯ä¾› task-scheduler è°ƒç”¨çš„ç®¡ç†æ¥å£ =====

from pydantic import BaseModel
from typing import List

class BatchUpdateRequest(BaseModel):
    symbols: List[str]
    data_types: List[str]  # ["stock_info", "stock_data", "fundamentals", "news"]
    start_date: Optional[str] = None
    end_date: Optional[str] = None

class CacheCleanupRequest(BaseModel):
    data_types: Optional[List[str]] = None  # æŒ‡å®šæ¸…ç†çš„æ•°æ®ç±»å‹ï¼ŒNoneè¡¨ç¤ºå…¨éƒ¨
    older_than_hours: Optional[int] = 24    # æ¸…ç†å¤šå°‘å°æ—¶å‰çš„æ•°æ®

@app.post("/api/admin/batch-update", response_model=APIResponse)
async def batch_update_data(
    request: BatchUpdateRequest,
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """æ‰¹é‡æ›´æ–°æ•°æ® - ä¾›è°ƒåº¦å™¨è°ƒç”¨"""
    try:
        logger.info(f"ğŸ”„ æ‰¹é‡æ›´æ–°æ•°æ®: {len(request.symbols)} åªè‚¡ç¥¨, æ•°æ®ç±»å‹: {request.data_types}")

        results = []
        total_success = 0
        total_failed = 0

        for symbol in request.symbols:
            symbol_results = {"symbol": symbol, "updates": []}

            for data_type in request.data_types:
                try:
                    if data_type == "stock_info":
                        # æ›´æ–°è‚¡ç¥¨ä¿¡æ¯
                        info_data = get_china_stock_info_unified(symbol)
                        if info_data and "é”™è¯¯" not in str(info_data):
                            # ç¼“å­˜æ•°æ®
                            if redis_client:
                                cache_key = f"stock_info:{symbol}"
                                stock_info = {
                                    "symbol": symbol,
                                    "name": "è‚¡ç¥¨åç§°",
                                    "market": "Aè‚¡",
                                    "data": info_data
                                }
                                import json
                                await redis_client.setex(
                                    cache_key, 3600,
                                    json.dumps(stock_info, ensure_ascii=False)
                                )
                            symbol_results["updates"].append({
                                "data_type": data_type,
                                "success": True
                            })
                            total_success += 1
                        else:
                            symbol_results["updates"].append({
                                "data_type": data_type,
                                "success": False,
                                "error": "æ•°æ®è·å–å¤±è´¥"
                            })
                            total_failed += 1

                    elif data_type == "stock_data":
                        # æ›´æ–°è‚¡ç¥¨æ•°æ®
                        start_date = request.start_date or "2025-01-01"
                        end_date = request.end_date or "2025-01-20"

                        stock_data = get_china_stock_data_unified(symbol, start_date, end_date)
                        if stock_data and "é”™è¯¯" not in str(stock_data):
                            # ç¼“å­˜æ•°æ®
                            if redis_client:
                                cache_key = f"stock_data:{symbol}:{start_date}:{end_date}"
                                parsed_data = {
                                    "symbol": symbol,
                                    "data": stock_data,
                                    "start_date": start_date,
                                    "end_date": end_date
                                }
                                import json
                                await redis_client.setex(
                                    cache_key, 1800,
                                    json.dumps(parsed_data, ensure_ascii=False)
                                )
                            symbol_results["updates"].append({
                                "data_type": data_type,
                                "success": True
                            })
                            total_success += 1
                        else:
                            symbol_results["updates"].append({
                                "data_type": data_type,
                                "success": False,
                                "error": "æ•°æ®è·å–å¤±è´¥"
                            })
                            total_failed += 1

                    elif data_type == "fundamentals":
                        # æ›´æ–°åŸºæœ¬é¢æ•°æ®
                        fundamentals_data = get_china_stock_fundamentals_tushare(symbol)
                        if fundamentals_data and "é”™è¯¯" not in str(fundamentals_data):
                            # ç¼“å­˜æ•°æ®
                            if redis_client:
                                from datetime import datetime
                                curr_date = datetime.now().strftime("%Y-%m-%d")
                                cache_key = f"fundamentals:{symbol}:{curr_date}"
                                result_data = {
                                    "symbol": symbol,
                                    "data": fundamentals_data,
                                    "date": curr_date
                                }
                                import json
                                await redis_client.setex(
                                    cache_key, 3600,
                                    json.dumps(result_data, ensure_ascii=False)
                                )
                            symbol_results["updates"].append({
                                "data_type": data_type,
                                "success": True
                            })
                            total_success += 1
                        else:
                            symbol_results["updates"].append({
                                "data_type": data_type,
                                "success": False,
                                "error": "æ•°æ®è·å–å¤±è´¥"
                            })
                            total_failed += 1

                    elif data_type == "news":
                        # æ›´æ–°æ–°é—»æ•°æ®
                        try:
                            from tradingagents.dataflows.realtime_news_utils import get_realtime_stock_news
                            from datetime import datetime
                            curr_date = datetime.now().strftime('%Y-%m-%d')
                            hours_back = 24 * 7
                            news_data = get_realtime_stock_news(symbol, curr_date, hours_back)
                        except ImportError:
                            from datetime import datetime
                            curr_date = datetime.now().strftime('%Y-%m-%d')
                            look_back_days = 7
                            news_data = get_finnhub_news(symbol, curr_date, look_back_days)

                        if news_data and "é”™è¯¯" not in str(news_data):
                            # ç¼“å­˜æ•°æ®
                            if redis_client:
                                cache_key = f"news:{symbol}"
                                result_data = {
                                    "symbol": symbol,
                                    "news": news_data
                                }
                                import json
                                await redis_client.setex(
                                    cache_key, 1800,
                                    json.dumps(result_data, ensure_ascii=False)
                                )
                            symbol_results["updates"].append({
                                "data_type": data_type,
                                "success": True
                            })
                            total_success += 1
                        else:
                            symbol_results["updates"].append({
                                "data_type": data_type,
                                "success": False,
                                "error": "æ•°æ®è·å–å¤±è´¥"
                            })
                            total_failed += 1

                    # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                    import asyncio
                    await asyncio.sleep(0.5)

                except Exception as e:
                    logger.warning(f"âš ï¸ æ›´æ–°å¤±è´¥: {symbol} - {data_type} - {e}")
                    symbol_results["updates"].append({
                        "data_type": data_type,
                        "success": False,
                        "error": str(e)
                    })
                    total_failed += 1

            results.append(symbol_results)

        return APIResponse(
            success=True,
            message=f"æ‰¹é‡æ›´æ–°å®Œæˆ: æˆåŠŸ {total_success}, å¤±è´¥ {total_failed}",
            data={
                "summary": {
                    "total_symbols": len(request.symbols),
                    "total_updates": total_success + total_failed,
                    "successful": total_success,
                    "failed": total_failed
                },
                "details": results
            }
        )

    except Exception as e:
        logger.error(f"âŒ æ‰¹é‡æ›´æ–°æ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡æ›´æ–°æ•°æ®å¤±è´¥: {str(e)}")

@app.post("/api/admin/cleanup-cache", response_model=APIResponse)
async def cleanup_cache(
    request: CacheCleanupRequest,
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """æ¸…ç†ç¼“å­˜æ•°æ® - ä¾›è°ƒåº¦å™¨è°ƒç”¨"""
    try:
        logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†ç¼“å­˜æ•°æ®")

        if not redis_client:
            return APIResponse(
                success=False,
                message="Redis æœªè¿æ¥ï¼Œæ— æ³•æ¸…ç†ç¼“å­˜"
            )

        cleaned_count = 0

        # è·å–æ‰€æœ‰ç¼“å­˜é”®
        if request.data_types:
            # æ¸…ç†æŒ‡å®šç±»å‹çš„ç¼“å­˜
            for data_type in request.data_types:
                pattern = f"{data_type}:*"
                keys = await redis_client.keys(pattern)
                if keys:
                    deleted = await redis_client.delete(*keys)
                    cleaned_count += deleted
                    logger.info(f"æ¸…ç† {data_type} ç¼“å­˜: {deleted} ä¸ªé”®")
        else:
            # æ¸…ç†æ‰€æœ‰æ•°æ®ç¼“å­˜
            patterns = ["stock_info:*", "stock_data:*", "fundamentals:*", "news:*"]
            for pattern in patterns:
                keys = await redis_client.keys(pattern)
                if keys:
                    deleted = await redis_client.delete(*keys)
                    cleaned_count += deleted
                    logger.info(f"æ¸…ç† {pattern} ç¼“å­˜: {deleted} ä¸ªé”®")

        return APIResponse(
            success=True,
            message=f"ç¼“å­˜æ¸…ç†å®Œæˆï¼Œæ¸…ç†äº† {cleaned_count} ä¸ªç¼“å­˜é¡¹",
            data={"cleaned_count": cleaned_count}
        )

    except Exception as e:
        logger.error(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†ç¼“å­˜å¤±è´¥: {str(e)}")

@app.get("/api/admin/statistics", response_model=APIResponse)
async def get_data_statistics(
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯ - ä¾›è°ƒåº¦å™¨è°ƒç”¨"""
    try:
        stats = {}

        if redis_client:
            # Redis ç»Ÿè®¡
            info = await redis_client.info()
            stats["redis"] = {
                "used_memory": info.get("used_memory_human", "N/A"),
                "connected_clients": info.get("connected_clients", 0),
                "total_commands_processed": info.get("total_commands_processed", 0)
            }

            # ç¼“å­˜æ•°æ®ç»Ÿè®¡
            cache_stats = {}
            data_types = ["stock_info", "stock_data", "fundamentals", "news"]
            for data_type in data_types:
                pattern = f"{data_type}:*"
                keys = await redis_client.keys(pattern)
                cache_stats[data_type] = len(keys)

            stats["cache_counts"] = cache_stats
        else:
            stats["redis"] = "not_connected"

        # MongoDB ç»Ÿè®¡ï¼ˆå¦‚æœè¿æ¥ï¼‰
        if db_manager and db_manager.is_connected():
            # è¿™é‡Œå¯ä»¥æ·»åŠ  MongoDB ç»Ÿè®¡ä¿¡æ¯
            stats["mongodb"] = {
                "status": "connected",
                "collections": []  # å¯ä»¥æ·»åŠ é›†åˆç»Ÿè®¡
            }
        else:
            stats["mongodb"] = "not_connected"

        return APIResponse(
            success=True,
            message="æ•°æ®ç»Ÿè®¡è·å–æˆåŠŸ",
            data=stats
        )

    except Exception as e:
        logger.error(f"âŒ è·å–æ•°æ®ç»Ÿè®¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æ•°æ®ç»Ÿè®¡å¤±è´¥: {str(e)}")

@app.post("/api/admin/preheat-cache", response_model=APIResponse)
async def preheat_cache(
    symbols: List[str],
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """é¢„çƒ­ç¼“å­˜ - ä¾›è°ƒåº¦å™¨è°ƒç”¨"""
    try:
        logger.info(f"ğŸ”¥ å¼€å§‹é¢„çƒ­ç¼“å­˜: {len(symbols)} åªè‚¡ç¥¨")

        preheated_count = 0

        for symbol in symbols:
            try:
                # é¢„çƒ­è‚¡ç¥¨ä¿¡æ¯
                info_data = get_china_stock_info_unified(symbol)
                if info_data and "é”™è¯¯" not in str(info_data) and redis_client:
                    cache_key = f"stock_info:{symbol}"
                    stock_info = {
                        "symbol": symbol,
                        "name": "è‚¡ç¥¨åç§°",
                        "market": "Aè‚¡",
                        "data": info_data
                    }
                    import json
                    await redis_client.setex(
                        cache_key, 3600,
                        json.dumps(stock_info, ensure_ascii=False)
                    )
                    preheated_count += 1

                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                import asyncio
                await asyncio.sleep(1)

            except Exception as e:
                logger.warning(f"âš ï¸ é¢„çƒ­å¤±è´¥: {symbol} - {e}")

        return APIResponse(
            success=True,
            message=f"ç¼“å­˜é¢„çƒ­å®Œæˆ: {preheated_count} åªè‚¡ç¥¨",
            data={"preheated_count": preheated_count}
        )

    except Exception as e:
        logger.error(f"âŒ ç¼“å­˜é¢„çƒ­å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ç¼“å­˜é¢„çƒ­å¤±è´¥: {str(e)}")


# ===== å¢å¼ºæ•°æ®æ¥å£ =====

@app.get("/api/enhanced/stock/{symbol}", response_model=APIResponse)
async def get_enhanced_stock_data(
    symbol: str,
    start_date: str = "2024-12-01",
    end_date: str = "2024-12-31",
    force_refresh: bool = False,
    clear_all_cache: bool = False
):
    """
    è·å–å¢å¼ºçš„è‚¡ç¥¨æ•°æ® - é›†æˆTradingAgentsä¼˜ç§€å®ç°

    Args:
        symbol: è‚¡ç¥¨ä»£ç  (å¦‚: AAPL, 000858, 00700)
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
        clear_all_cache: æ˜¯å¦æ¸…é™¤æ‰€æœ‰ç¼“å­˜ï¼ˆåŒ…æ‹¬æ•°æ®æºç¼“å­˜ï¼‰
    """
    try:
        # Debug: è®°å½•APIè°ƒç”¨
        debug_logger.debug_api_request_received("GET", f"/api/enhanced/stock/{symbol}")
        debug_logger.debug_validation_start("symbol")

        if not symbol or len(symbol.strip()) == 0:
            debug_logger.debug_validation_failed("symbol", "empty_or_invalid")
            raise HTTPException(status_code=400, detail="è‚¡ç¥¨ä»£ç ä¸èƒ½ä¸ºç©º")

        debug_logger.debug_validation_passed("symbol")

        # è·å–å¢å¼ºæ•°æ®ç®¡ç†å™¨
        enhanced_manager = get_enhanced_data_manager()

        # å¦‚æœéœ€è¦æ¸…é™¤æ‰€æœ‰ç¼“å­˜ï¼Œå…ˆæ¸…é™¤æ•°æ®æºç¼“å­˜
        if clear_all_cache:
            try:
                # æ¸…é™¤æ•°æ®æºå·¥å‚çš„ç¼“å­˜
                from .datasources.factory import get_data_source_factory
                factory = get_data_source_factory()
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ¸…é™¤æ•°æ®æºç¼“å­˜çš„é€»è¾‘
                logger.info(f"ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰ç¼“å­˜: {symbol}")
                force_refresh = True  # åŒæ—¶å¼ºåˆ¶åˆ·æ–°
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…é™¤ç¼“å­˜å¤±è´¥: {e}")

        # è·å–å¢å¼ºè‚¡ç¥¨æ•°æ®
        result = await enhanced_manager.get_enhanced_stock_data(
            symbol=symbol.upper(),
            start_date=start_date,
            end_date=end_date,
            force_refresh=force_refresh
        )

        debug_logger.debug_api_response_prepared(200)

        # ä½¿ç”¨å›½é™…åŒ–å“åº”
        return i18n_response.success_response("api.success.enhanced_stock_data", result)

    except HTTPException:
        raise
    except Exception as e:
        debug_logger.debug("log.debug.api.internal_error", symbol=symbol, error=str(e))
        logger.error(f"âŒ è·å–å¢å¼ºè‚¡ç¥¨æ•°æ®å¤±è´¥: {symbol} - {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å¢å¼ºè‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}")


@app.get("/api/enhanced/stock/{symbol}/formatted")
async def get_enhanced_stock_data_formatted(
    symbol: str,
    start_date: str = "2024-12-01",
    end_date: str = "2024-12-31",
    force_refresh: bool = False
):
    """
    è·å–å¢å¼ºçš„è‚¡ç¥¨æ•°æ® - è¿”å›æ ¼å¼åŒ–çš„æ–‡æœ¬æ•°æ® (TradingAgentsé£æ ¼)
    """
    try:
        # è·å–å¢å¼ºæ•°æ®ç®¡ç†å™¨
        enhanced_manager = get_enhanced_data_manager()

        # è·å–å¢å¼ºè‚¡ç¥¨æ•°æ®
        result = await enhanced_manager.get_enhanced_stock_data(
            symbol=symbol.upper(),
            start_date=start_date,
            end_date=end_date,
            force_refresh=force_refresh
        )

        # è¿”å›æ ¼å¼åŒ–çš„æ–‡æœ¬æ•°æ®
        from fastapi.responses import PlainTextResponse
        return PlainTextResponse(
            content=result.get("formatted_data", "æ•°æ®è·å–å¤±è´¥"),
            media_type="text/plain; charset=utf-8"
        )

    except Exception as e:
        logger.error(f"âŒ è·å–æ ¼å¼åŒ–è‚¡ç¥¨æ•°æ®å¤±è´¥: {symbol} - {e}")
        return PlainTextResponse(
            content=f"âŒ è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {str(e)}",
            media_type="text/plain; charset=utf-8"
        )


# ===== v1 APIå…¼å®¹æ€§ç«¯ç‚¹ (ç”¨äºæ™ºèƒ½ä½“è°ƒç”¨) =====

@app.get("/api/v1/market/data", response_model=APIResponse)
async def get_market_data_v1(
    market: str,
    data_type: str = "US",
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """è·å–å¸‚åœºæ•°æ® (v1å…¼å®¹æ¥å£)"""
    try:
        # å°†v1å‚æ•°æ˜ å°„åˆ°ç°æœ‰çš„è‚¡ç¥¨ä¿¡æ¯æ¥å£
        return await get_stock_info(market, force_refresh=False, redis_client=redis_client)
    except Exception as e:
        logger.error(f"âŒ è·å–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å¸‚åœºæ•°æ®å¤±è´¥: {str(e)}")

@app.get("/api/v1/company/info", response_model=APIResponse)
async def get_company_info_v1(
    symbol: str,
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """è·å–å…¬å¸ä¿¡æ¯ (v1å…¼å®¹æ¥å£)"""
    try:
        # æ˜ å°„åˆ°ç°æœ‰çš„è‚¡ç¥¨ä¿¡æ¯æ¥å£
        return await get_stock_info(symbol, force_refresh=False, redis_client=redis_client)
    except Exception as e:
        logger.error(f"âŒ è·å–å…¬å¸ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å…¬å¸ä¿¡æ¯å¤±è´¥: {str(e)}")

@app.get("/api/v1/financial/income", response_model=APIResponse)
async def get_financial_income_v1(
    symbol: str,
    period: str = "annual",
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """è·å–æŸç›Šè¡¨æ•°æ® (v1å…¼å®¹æ¥å£)"""
    try:
        # æ˜ å°„åˆ°ç°æœ‰çš„åŸºæœ¬é¢æ•°æ®æ¥å£
        # ä½¿ç”¨é»˜è®¤çš„æ—¥æœŸèŒƒå›´
        start_date = "2023-01-01"
        end_date = "2024-12-31"
        curr_date = "2024-12-31"
        return await get_stock_fundamentals(symbol, start_date, end_date, curr_date, redis_client=redis_client)
    except Exception as e:
        logger.error(f"âŒ è·å–æŸç›Šè¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æŸç›Šè¡¨å¤±è´¥: {str(e)}")

@app.get("/api/v1/market/history", response_model=APIResponse)
async def get_market_history_v1(
    symbol: str,
    period: str = "1y",
    interval: str = "1d",
    redis_client: Optional[redis.Redis] = Depends(get_redis)
):
    """è·å–ä»·æ ¼å†å²æ•°æ® (v1å…¼å®¹æ¥å£)"""
    try:
        # ä½¿ç”¨ç‹¬ç«‹çš„å¸‚åœºåˆ¤æ–­é€»è¾‘
        import sys
        from pathlib import Path

        # æ·»åŠ sharedè·¯å¾„
        shared_path = Path(__file__).parent.parent.parent / "shared"
        sys.path.insert(0, str(shared_path))

        from utils.stock_utils import StockUtils
        from datetime import datetime

        current_date = datetime.now().strftime("%Y-%m-%d")
        start_date = "2024-01-01"  # é»˜è®¤å¼€å§‹æ—¥æœŸ

        # åˆ¤æ–­å¸‚åœºç±»å‹
        market_info = StockUtils.get_market_info(symbol)

        if market_info['is_us']:
            # ç¾è‚¡ï¼šç›®å‰è¿”å›å ä½ç¬¦ï¼Œåç»­å¯æ¥å…¥ç¾è‚¡æ•°æ®æº
            return APIResponse(
                success=True,
                message=f"è·å–{symbol}ä»·æ ¼å†å²æˆåŠŸ",
                data={
                    "symbol": symbol,
                    "market": "US",
                    "start_date": start_date,
                    "end_date": current_date,
                    "period": period,
                    "interval": interval,
                    "message": "ç¾è‚¡æ•°æ®æ¥å£å¼€å‘ä¸­ï¼Œè¯·ä½¿ç”¨ç°æœ‰çš„è‚¡ç¥¨æ•°æ®æ¥å£"
                }
            )
        elif market_info['is_china'] or market_info['is_hk']:
            # Aè‚¡/æ¸¯è‚¡ï¼šè°ƒç”¨ç°æœ‰çš„è‚¡ç¥¨æ•°æ®æ¥å£
            request = StockDataRequest(
                symbol=symbol,
                start_date=start_date,
                end_date=current_date,
                period=interval
            )
            return await get_stock_data(request, redis_client=redis_client)
        else:
            # æœªçŸ¥å¸‚åœº
            return APIResponse(
                success=False,
                message=f"æ— æ³•è¯†åˆ«è‚¡ç¥¨å¸‚åœº: {symbol}",
                data={"symbol": symbol, "market": "UNKNOWN"}
            )
    except Exception as e:
        logger.error(f"âŒ è·å–ä»·æ ¼å†å²å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–ä»·æ ¼å†å²å¤±è´¥: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    import sys
    from pathlib import Path

    # æ·»åŠ sharedè·¯å¾„
    shared_path = Path(__file__).parent.parent.parent / "shared"
    sys.path.insert(0, str(shared_path))

    from utils.config import get_config

    config = get_config()
    uvicorn.run(
        "app.main:app",
        host="0.0.0.0",
        port=config.get('DATA_SERVICE_PORT', 8002),
        reload=False,  # æš‚æ—¶å…³é—­reloadé¿å…é¢‘ç¹ç›‘æ§æ—¥å¿—
        log_level=config.get('LOG_LEVEL', 'INFO').lower(),
        reload_excludes=[
            "logs/*",
            "results/*",
            "data/*",
            "*/__pycache__/*",
            "*.log",
            "*.pyc"
        ]
    )
