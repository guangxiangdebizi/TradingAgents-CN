#!/usr/bin/env python3
"""
MongoDB æ•°æ®æŸ¥çœ‹å·¥å…·
"""

import sys
import json
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

try:
    from pymongo import MongoClient
    import redis
except ImportError:
    print("âŒ è¯·å®‰è£…ä¾èµ–: pip install pymongo redis")
    sys.exit(1)

class MongoDBDataViewer:
    """MongoDB æ•°æ®æŸ¥çœ‹å™¨"""
    
    def __init__(self):
        try:
            # è¿æ¥ MongoDB (å¸¦è®¤è¯)
            self.mongodb = MongoClient("mongodb://admin:tradingagents123@localhost:27017/tradingagents?authSource=admin")
            self.db = self.mongodb.tradingagents

            # è¿æ¥ Redis
            self.redis = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)

            print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            sys.exit(1)
    
    def show_collections_info(self):
        """æ˜¾ç¤ºé›†åˆä¿¡æ¯"""
        print("ğŸ“Š MongoDB é›†åˆä¿¡æ¯")
        print("=" * 50)
        
        collections = self.db.list_collection_names()
        
        for collection_name in collections:
            collection = self.db[collection_name]
            count = collection.count_documents({})
            print(f"ğŸ“‹ {collection_name}: {count} æ¡è®°å½•")
            
            # æ˜¾ç¤ºæœ€æ–°çš„ä¸€æ¡è®°å½•
            if count > 0:
                latest = collection.find_one(sort=[("_id", -1)])
                if latest:
                    # ç§»é™¤ _id å­—æ®µä»¥ä¾¿æ˜¾ç¤º
                    latest.pop("_id", None)
                    print(f"   æœ€æ–°è®°å½•: {json.dumps(latest, default=str, ensure_ascii=False)[:100]}...")
        
        print(f"\nğŸ“Š æ€»è®¡: {len(collections)} ä¸ªé›†åˆ")
    
    def show_cached_data(self):
        """æ˜¾ç¤ºç¼“å­˜æ•°æ®"""
        print("\nğŸ“¦ ç¼“å­˜æ•°æ®è¯¦æƒ…")
        print("=" * 50)
        
        # MongoDB ç¼“å­˜
        cached_data = list(self.db.cached_data.find().sort("timestamp", -1))
        print(f"ğŸ“‹ MongoDB ç¼“å­˜: {len(cached_data)} æ¡è®°å½•")
        
        for data in cached_data[:10]:  # æ˜¾ç¤ºæœ€æ–°10æ¡
            print(f"  ğŸ”¹ {data.get('symbol')} - {data.get('data_type')}")
            print(f"     æ¥æº: {data.get('source')}")
            print(f"     æ—¶é—´: {data.get('timestamp')}")
            print(f"     è¿‡æœŸ: {data.get('expires_at')}")
            print()
        
        # Redis ç¼“å­˜
        try:
            redis_keys = self.redis.keys("data:*")
            print(f"ğŸ”´ Redis ç¼“å­˜: {len(redis_keys)} ä¸ªé”®")
            
            for key in redis_keys[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                ttl = self.redis.ttl(key)
                print(f"  ğŸ”¹ {key} (TTL: {ttl}ç§’)")
        except Exception as e:
            print(f"âŒ Redis æŸ¥è¯¢å¤±è´¥: {e}")
    
    def show_stock_data(self, symbol: str = None):
        """æ˜¾ç¤ºè‚¡ç¥¨æ•°æ®"""
        print(f"\nğŸ“ˆ è‚¡ç¥¨æ•°æ® {f'({symbol})' if symbol else ''}")
        print("=" * 50)
        
        query = {"symbol": symbol} if symbol else {}
        
        # è‚¡ç¥¨ä¿¡æ¯
        stock_info = list(self.db.stock_info.find(query).limit(5))
        print(f"ğŸ“‹ è‚¡ç¥¨ä¿¡æ¯: {len(stock_info)} æ¡è®°å½•")
        for info in stock_info:
            data = info.get("data", {})
            print(f"  ğŸ”¹ {info.get('symbol')}: {data.get('name', 'N/A')}")
            print(f"     æ¥æº: {info.get('source', 'N/A')}")
            print(f"     æ›´æ–°: {info.get('updated_at', 'N/A')}")
        
        # è‚¡ç¥¨ä»·æ ¼æ•°æ®
        stock_data = list(self.db.stock_data.find(query).sort("date", -1).limit(10))
        print(f"\nğŸ“Š è‚¡ç¥¨ä»·æ ¼æ•°æ®: {len(stock_data)} æ¡è®°å½•")
        for data in stock_data:
            print(f"  ğŸ”¹ {data.get('symbol')} - {data.get('date')}")
            print(f"     å¼€ç›˜: {data.get('open')}, æ”¶ç›˜: {data.get('close')}")
            print(f"     æˆäº¤é‡: {data.get('volume')}")
            print(f"     æ¥æº: {data.get('source', 'N/A')}")
        
        # åŸºæœ¬é¢æ•°æ®
        fundamentals = list(self.db.fundamentals.find(query).sort("report_date", -1).limit(5))
        print(f"\nğŸ’° åŸºæœ¬é¢æ•°æ®: {len(fundamentals)} æ¡è®°å½•")
        for fund in fundamentals:
            data = fund.get("data", {})
            print(f"  ğŸ”¹ {fund.get('symbol')} - {fund.get('report_date')}")
            print(f"     ROE: {data.get('roe', 'N/A')}, PE: {data.get('pe_ratio', 'N/A')}")
            print(f"     æ¥æº: {fund.get('source', 'N/A')}")
        
        # æ–°é—»æ•°æ®
        news = list(self.db.news.find(query).sort("publish_time", -1).limit(5))
        print(f"\nğŸ“° æ–°é—»æ•°æ®: {len(news)} æ¡è®°å½•")
        for item in news:
            print(f"  ğŸ”¹ {item.get('symbol')}: {item.get('title', 'N/A')[:50]}...")
            print(f"     å‘å¸ƒ: {item.get('publish_time', 'N/A')}")
            print(f"     æ¥æº: {item.get('source', 'N/A')}")
    
    def show_data_statistics(self):
        """æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡"""
        print("\nğŸ“Š æ•°æ®ç»Ÿè®¡")
        print("=" * 50)
        
        # æŒ‰æ•°æ®æºç»Ÿè®¡
        print("ğŸ“‹ æŒ‰æ•°æ®æºç»Ÿè®¡:")
        pipeline = [
            {"$group": {"_id": "$source", "count": {"$sum": 1}}},
            {"$sort": {"count": -1}}
        ]
        
        for collection_name in ["stock_info", "stock_data", "fundamentals", "news"]:
            collection = self.db[collection_name]
            results = list(collection.aggregate(pipeline))
            if results:
                print(f"  {collection_name}:")
                for result in results:
                    print(f"    {result['_id']}: {result['count']} æ¡")
        
        # æŒ‰è‚¡ç¥¨ç»Ÿè®¡
        print("\nğŸ“ˆ æŒ‰è‚¡ç¥¨ç»Ÿè®¡ (Top 10):")
        for collection_name in ["stock_info", "stock_data"]:
            collection = self.db[collection_name]
            pipeline = [
                {"$group": {"_id": "$symbol", "count": {"$sum": 1}}},
                {"$sort": {"count": -1}},
                {"$limit": 10}
            ]
            results = list(collection.aggregate(pipeline))
            if results:
                print(f"  {collection_name}:")
                for result in results:
                    print(f"    {result['_id']}: {result['count']} æ¡")
        
        # æŒ‰æ—¥æœŸç»Ÿè®¡
        print("\nğŸ“… æœ€è¿‘æ•°æ®æ›´æ–°:")
        for collection_name in ["stock_info", "stock_data", "fundamentals", "news"]:
            collection = self.db[collection_name]
            latest = collection.find_one(sort=[("updated_at", -1)])
            if latest:
                print(f"  {collection_name}: {latest.get('updated_at', 'N/A')}")
    
    def cleanup_test_data(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        print("\nğŸ§¹ æ¸…ç†æµ‹è¯•æ•°æ®")
        print("=" * 50)
        
        # æ¸…ç†è¿‡æœŸç¼“å­˜
        cutoff_date = datetime.now() - timedelta(days=1)
        
        collections_to_clean = ["cached_data"]
        
        for collection_name in collections_to_clean:
            collection = self.db[collection_name]
            result = collection.delete_many({
                "expires_at": {"$lt": cutoff_date}
            })
            print(f"ğŸ“‹ {collection_name}: æ¸…ç†äº† {result.deleted_count} æ¡è¿‡æœŸè®°å½•")
        
        # æ¸…ç† Redis è¿‡æœŸé”®
        try:
            redis_keys = self.redis.keys("data:*")
            expired_count = 0
            for key in redis_keys:
                ttl = self.redis.ttl(key)
                if ttl == -2:  # é”®å·²è¿‡æœŸ
                    self.redis.delete(key)
                    expired_count += 1
            print(f"ğŸ”´ Redis: æ¸…ç†äº† {expired_count} ä¸ªè¿‡æœŸé”®")
        except Exception as e:
            print(f"âŒ Redis æ¸…ç†å¤±è´¥: {e}")
    
    def export_data(self, symbol: str, output_file: str):
        """å¯¼å‡ºæ•°æ®"""
        print(f"\nğŸ“¤ å¯¼å‡º {symbol} çš„æ•°æ®åˆ° {output_file}")
        print("=" * 50)
        
        export_data = {
            "symbol": symbol,
            "export_time": datetime.now().isoformat(),
            "stock_info": None,
            "stock_data": [],
            "fundamentals": [],
            "news": []
        }
        
        # å¯¼å‡ºè‚¡ç¥¨ä¿¡æ¯
        stock_info = self.db.stock_info.find_one({"symbol": symbol})
        if stock_info:
            stock_info.pop("_id", None)
            export_data["stock_info"] = stock_info
        
        # å¯¼å‡ºè‚¡ç¥¨æ•°æ®
        stock_data = list(self.db.stock_data.find({"symbol": symbol}).sort("date", -1))
        for data in stock_data:
            data.pop("_id", None)
            export_data["stock_data"].append(data)
        
        # å¯¼å‡ºåŸºæœ¬é¢æ•°æ®
        fundamentals = list(self.db.fundamentals.find({"symbol": symbol}).sort("report_date", -1))
        for data in fundamentals:
            data.pop("_id", None)
            export_data["fundamentals"].append(data)
        
        # å¯¼å‡ºæ–°é—»æ•°æ®
        news = list(self.db.news.find({"symbol": symbol}).sort("publish_time", -1).limit(50))
        for data in news:
            data.pop("_id", None)
            export_data["news"].append(data)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"âœ… å¯¼å‡ºå®Œæˆ:")
            print(f"   è‚¡ç¥¨ä¿¡æ¯: {'æœ‰' if export_data['stock_info'] else 'æ— '}")
            print(f"   è‚¡ç¥¨æ•°æ®: {len(export_data['stock_data'])} æ¡")
            print(f"   åŸºæœ¬é¢æ•°æ®: {len(export_data['fundamentals'])} æ¡")
            print(f"   æ–°é—»æ•°æ®: {len(export_data['news'])} æ¡")
            
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    viewer = MongoDBDataViewer()
    
    if len(sys.argv) < 2:
        print("ğŸ” TradingAgents MongoDB æ•°æ®æŸ¥çœ‹å·¥å…·")
        print("=" * 50)
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python mongodb_data_viewer.py <å‘½ä»¤> [å‚æ•°]")
        print("")
        print("å¯ç”¨å‘½ä»¤:")
        print("  info              - æ˜¾ç¤ºé›†åˆä¿¡æ¯")
        print("  cache             - æ˜¾ç¤ºç¼“å­˜æ•°æ®")
        print("  stock [symbol]    - æ˜¾ç¤ºè‚¡ç¥¨æ•°æ®")
        print("  stats             - æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡")
        print("  cleanup           - æ¸…ç†æµ‹è¯•æ•°æ®")
        print("  export <symbol> <file> - å¯¼å‡ºè‚¡ç¥¨æ•°æ®")
        print("")
        print("ç¤ºä¾‹:")
        print("  python mongodb_data_viewer.py info")
        print("  python mongodb_data_viewer.py stock 000858")
        print("  python mongodb_data_viewer.py export 000858 data.json")
        return
    
    command = sys.argv[1].lower()
    
    if command == "info":
        viewer.show_collections_info()
    elif command == "cache":
        viewer.show_cached_data()
    elif command == "stock":
        symbol = sys.argv[2] if len(sys.argv) > 2 else None
        viewer.show_stock_data(symbol)
    elif command == "stats":
        viewer.show_data_statistics()
    elif command == "cleanup":
        viewer.cleanup_test_data()
    elif command == "export":
        if len(sys.argv) < 4:
            print("âŒ è¯·æŒ‡å®šè‚¡ç¥¨ä»£ç å’Œè¾“å‡ºæ–‡ä»¶")
            return
        symbol = sys.argv[2]
        output_file = sys.argv[3]
        viewer.export_data(symbol, output_file)
    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")

if __name__ == "__main__":
    main()
