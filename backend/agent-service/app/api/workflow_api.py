"""
å·¥ä½œæµAPIè·¯ç”±
æä¾›é«˜çº§å·¥ä½œæµç®¡ç†çš„REST APIæ¥å£
"""

import uuid
from typing import Dict, List, Any, Optional
from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks
from fastapi.responses import JSONResponse

from backend.shared.logging_config import get_logger
from ..orchestration.workflow_manager import WorkflowManager, WorkflowDefinition
from ..utils.state_manager import StateManager

logger = get_logger("agent-service.workflow_api")

router = APIRouter()


def get_workflow_manager() -> WorkflowManager:
    """è·å–å·¥ä½œæµç®¡ç†å™¨ä¾èµ–"""
    from ..main import workflow_manager
    if workflow_manager is None:
        raise HTTPException(status_code=503, detail="Workflow Manageræœªåˆå§‹åŒ–")
    return workflow_manager


def get_state_manager() -> StateManager:
    """è·å–çŠ¶æ€ç®¡ç†å™¨ä¾èµ–"""
    from ..main import state_manager
    if state_manager is None:
        raise HTTPException(status_code=503, detail="State Manageræœªåˆå§‹åŒ–")
    return state_manager


@router.post("/start")
async def start_workflow(
    workflow_id: str,
    context: Dict[str, Any],
    execution_id: Optional[str] = None,
    manager: WorkflowManager = Depends(get_workflow_manager)
):
    """å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ"""
    try:
        execution_id = await manager.start_workflow(
            workflow_id=workflow_id,
            context=context,
            execution_id=execution_id
        )
        
        logger.info(f"ğŸš€ å¯åŠ¨å·¥ä½œæµ: {execution_id} - {workflow_id}")
        return {
            "execution_id": execution_id,
            "workflow_id": workflow_id,
            "status": "started",
            "message": "å·¥ä½œæµå·²å¯åŠ¨"
        }
        
    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨å·¥ä½œæµå¤±è´¥: {workflow_id} - {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/executions/{execution_id}/status")
async def get_execution_status(
    execution_id: str,
    manager: WorkflowManager = Depends(get_workflow_manager)
):
    """è·å–å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€"""
    try:
        status = await manager.get_execution_status(execution_id)
        if not status:
            raise HTTPException(status_code=404, detail=f"å·¥ä½œæµæ‰§è¡Œä¸å­˜åœ¨: {execution_id}")
        
        logger.info(f"ğŸ“Š è·å–å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€: {execution_id}")
        return status
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€å¤±è´¥: {execution_id} - {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/executions/{execution_id}/cancel")
async def cancel_execution(
    execution_id: str,
    manager: WorkflowManager = Depends(get_workflow_manager)
):
    """å–æ¶ˆå·¥ä½œæµæ‰§è¡Œ"""
    try:
        success = await manager.cancel_execution(execution_id)
        if not success:
            raise HTTPException(status_code=404, detail=f"å·¥ä½œæµæ‰§è¡Œä¸å­˜åœ¨: {execution_id}")
        
        logger.info(f"ğŸš« å–æ¶ˆå·¥ä½œæµæ‰§è¡Œ: {execution_id}")
        return {"message": f"å·¥ä½œæµæ‰§è¡Œå·²å–æ¶ˆ: {execution_id}"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å–æ¶ˆå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {execution_id} - {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/definitions")
async def get_workflow_definitions(
    manager: WorkflowManager = Depends(get_workflow_manager)
):
    """è·å–æ‰€æœ‰å·¥ä½œæµå®šä¹‰"""
    try:
        definitions = manager.get_workflow_definitions()
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable_definitions = {}
        for workflow_id, definition in definitions.items():
            serializable_definitions[workflow_id] = {
                "workflow_id": definition.workflow_id,
                "name": definition.name,
                "description": definition.description,
                "version": definition.version,
                "steps_count": len(definition.steps),
                "global_timeout": definition.global_timeout,
                "failure_strategy": definition.failure_strategy,
                "metadata": definition.metadata
            }
        
        logger.info(f"ğŸ“‹ è·å–å·¥ä½œæµå®šä¹‰: {len(serializable_definitions)}ä¸ª")
        return {"definitions": serializable_definitions}
        
    except Exception as e:
        logger.error(f"âŒ è·å–å·¥ä½œæµå®šä¹‰å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/definitions/{workflow_id}")
async def get_workflow_definition(
    workflow_id: str,
    manager: WorkflowManager = Depends(get_workflow_manager)
):
    """è·å–ç‰¹å®šå·¥ä½œæµå®šä¹‰"""
    try:
        definitions = manager.get_workflow_definitions()
        definition = definitions.get(workflow_id)
        
        if not definition:
            raise HTTPException(status_code=404, detail=f"å·¥ä½œæµå®šä¹‰ä¸å­˜åœ¨: {workflow_id}")
        
        # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
        serializable_definition = {
            "workflow_id": definition.workflow_id,
            "name": definition.name,
            "description": definition.description,
            "version": definition.version,
            "global_timeout": definition.global_timeout,
            "failure_strategy": definition.failure_strategy,
            "metadata": definition.metadata,
            "steps": []
        }
        
        # æ·»åŠ æ­¥éª¤ä¿¡æ¯
        for step in definition.steps:
            step_info = {
                "step_id": step.step_id,
                "name": step.name,
                "agent_types": step.agent_types,
                "dependencies": step.dependencies,
                "parallel": step.parallel,
                "optional": step.optional,
                "timeout": step.timeout,
                "max_retries": step.max_retries,
                "parameters": step.parameters
            }
            serializable_definition["steps"].append(step_info)
        
        logger.info(f"ğŸ“‹ è·å–å·¥ä½œæµå®šä¹‰: {workflow_id}")
        return serializable_definition
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–å·¥ä½œæµå®šä¹‰å¤±è´¥: {workflow_id} - {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/executions")
async def get_active_executions(
    manager: WorkflowManager = Depends(get_workflow_manager)
):
    """è·å–æ´»è·ƒçš„å·¥ä½œæµæ‰§è¡Œ"""
    try:
        active_executions = []
        
        for execution_id, execution in manager.active_executions.items():
            active_executions.append({
                "execution_id": execution_id,
                "workflow_id": execution.workflow_id,
                "status": execution.status.value,
                "current_step_index": execution.current_step_index,
                "completed_steps": len(execution.completed_steps),
                "failed_steps": len(execution.failed_steps),
                "started_at": execution.started_at.isoformat(),
                "completed_at": execution.completed_at.isoformat() if execution.completed_at else None
            })
        
        logger.info(f"ğŸ“Š è·å–æ´»è·ƒå·¥ä½œæµæ‰§è¡Œ: {len(active_executions)}ä¸ª")
        return {"active_executions": active_executions}
        
    except Exception as e:
        logger.error(f"âŒ è·å–æ´»è·ƒå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/validate")
async def validate_workflow_context(
    workflow_id: str,
    context: Dict[str, Any],
    manager: WorkflowManager = Depends(get_workflow_manager)
):
    """éªŒè¯å·¥ä½œæµä¸Šä¸‹æ–‡"""
    try:
        definitions = manager.get_workflow_definitions()
        definition = definitions.get(workflow_id)
        
        if not definition:
            raise HTTPException(status_code=404, detail=f"å·¥ä½œæµå®šä¹‰ä¸å­˜åœ¨: {workflow_id}")
        
        # éªŒè¯å¿…éœ€çš„ä¸Šä¸‹æ–‡å­—æ®µ
        required_fields = ["symbol", "company_name", "market", "analysis_date"]
        missing_fields = [field for field in required_fields if field not in context]
        
        if missing_fields:
            return {
                "valid": False,
                "missing_fields": missing_fields,
                "message": f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {', '.join(missing_fields)}"
            }
        
        # éªŒè¯æ™ºèƒ½ä½“ç±»å‹
        all_agent_types = set()
        for step in definition.steps:
            all_agent_types.update(step.agent_types)
        
        # ä¼°ç®—æ‰§è¡Œæ—¶é—´
        estimated_duration = sum(step.timeout for step in definition.steps)
        
        logger.info(f"âœ… å·¥ä½œæµä¸Šä¸‹æ–‡éªŒè¯é€šè¿‡: {workflow_id}")
        return {
            "valid": True,
            "required_agent_types": list(all_agent_types),
            "estimated_duration": estimated_duration,
            "total_steps": len(definition.steps),
            "message": "ä¸Šä¸‹æ–‡éªŒè¯é€šè¿‡"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ å·¥ä½œæµä¸Šä¸‹æ–‡éªŒè¯å¤±è´¥: {workflow_id} - {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/test")
async def test_workflow(
    workflow_id: str = "quick_analysis_v2",
    symbol: str = "AAPL",
    manager: WorkflowManager = Depends(get_workflow_manager)
):
    """æµ‹è¯•å·¥ä½œæµåŠŸèƒ½"""
    try:
        # åˆ›å»ºæµ‹è¯•ä¸Šä¸‹æ–‡
        context = {
            "symbol": symbol,
            "company_name": "Apple Inc.",
            "market": "US",
            "analysis_date": "2025-01-22",
            "test_mode": True
        }
        
        # å¯åŠ¨æµ‹è¯•å·¥ä½œæµ
        execution_id = await manager.start_workflow(
            workflow_id=workflow_id,
            context=context
        )
        
        logger.info(f"ğŸ§ª å¯åŠ¨æµ‹è¯•å·¥ä½œæµ: {execution_id}")
        return {
            "execution_id": execution_id,
            "workflow_id": workflow_id,
            "context": context,
            "message": "æµ‹è¯•å·¥ä½œæµå·²å¯åŠ¨"
        }
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å·¥ä½œæµå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/statistics")
async def get_workflow_statistics(
    manager: WorkflowManager = Depends(get_workflow_manager),
    state_manager: StateManager = Depends(get_state_manager)
):
    """è·å–å·¥ä½œæµç»Ÿè®¡ä¿¡æ¯"""
    try:
        # å½“å‰æ´»è·ƒæ‰§è¡Œ
        active_count = len(manager.active_executions)
        
        # å¯ç”¨å·¥ä½œæµå®šä¹‰
        definitions_count = len(manager.workflow_definitions)
        
        # æ¨¡æ‹Ÿå†å²ç»Ÿè®¡æ•°æ®
        total_executions = active_count + 25
        completed_executions = 20
        failed_executions = 5
        
        # å·¥ä½œæµä½¿ç”¨ç»Ÿè®¡
        workflow_usage = {}
        for execution in manager.active_executions.values():
            workflow_id = execution.workflow_id
            workflow_usage[workflow_id] = workflow_usage.get(workflow_id, 0) + 1
        
        # æ­¥éª¤æˆåŠŸç‡ç»Ÿè®¡
        step_success_rates = {
            "data_preparation": 0.95,
            "parallel_analysis": 0.90,
            "research_debate": 0.85,
            "risk_assessment": 0.88,
            "management_review": 0.92,
            "final_decision": 0.87
        }
        
        statistics = {
            "current_active": active_count,
            "total_executions": total_executions,
            "completed_executions": completed_executions,
            "failed_executions": failed_executions,
            "success_rate": completed_executions / max(total_executions, 1),
            "available_definitions": definitions_count,
            "workflow_usage": workflow_usage,
            "step_success_rates": step_success_rates,
            "average_execution_time": 450  # ç§’
        }
        
        logger.info(f"ğŸ“Š è·å–å·¥ä½œæµç»Ÿè®¡ä¿¡æ¯")
        return statistics
        
    except Exception as e:
        logger.error(f"âŒ è·å–å·¥ä½œæµç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
