"""
å·¥ä½œæµç®¡ç†å™¨
è´Ÿè´£å¤æ‚å·¥ä½œæµçš„å®šä¹‰ã€æ‰§è¡Œå’Œç®¡ç†
"""

import asyncio
import uuid
from typing import Dict, List, Any, Optional, Callable
from datetime import datetime
from enum import Enum
from dataclasses import dataclass, field

from backend.shared.logging_config import get_logger

logger = get_logger("agent-service.workflow_manager")


class WorkflowStatus(Enum):
    """å·¥ä½œæµçŠ¶æ€æšä¸¾"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    PAUSED = "paused"


class StepStatus(Enum):
    """æ­¥éª¤çŠ¶æ€æšä¸¾"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    SKIPPED = "skipped"


@dataclass
class WorkflowStep:
    """å·¥ä½œæµæ­¥éª¤"""
    step_id: str
    name: str
    agent_types: List[str]
    dependencies: List[str] = field(default_factory=list)
    parallel: bool = False
    optional: bool = False
    timeout: int = 300
    retry_count: int = 0
    max_retries: int = 3
    condition: Optional[Callable] = None
    parameters: Dict[str, Any] = field(default_factory=dict)
    
    # è¿è¡Œæ—¶çŠ¶æ€
    status: StepStatus = StepStatus.PENDING
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    results: Dict[str, Any] = field(default_factory=dict)
    error: Optional[str] = None


@dataclass
class WorkflowDefinition:
    """å·¥ä½œæµå®šä¹‰"""
    workflow_id: str
    name: str
    description: str
    version: str
    steps: List[WorkflowStep]
    global_timeout: int = 1800
    failure_strategy: str = "stop"  # stop, continue, retry
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class WorkflowExecution:
    """å·¥ä½œæµæ‰§è¡Œå®ä¾‹"""
    execution_id: str
    workflow_id: str
    status: WorkflowStatus
    context: Dict[str, Any]
    current_step_index: int = 0
    completed_steps: List[str] = field(default_factory=list)
    failed_steps: List[str] = field(default_factory=list)
    step_results: Dict[str, Any] = field(default_factory=dict)
    started_at: datetime = field(default_factory=datetime.now)
    completed_at: Optional[datetime] = None
    error: Optional[str] = None
    final_result: Dict[str, Any] = field(default_factory=dict)


class WorkflowManager:
    """å·¥ä½œæµç®¡ç†å™¨"""
    
    def __init__(self, agent_manager, state_manager, collaboration_engine):
        self.agent_manager = agent_manager
        self.state_manager = state_manager
        self.collaboration_engine = collaboration_engine
        
        # å·¥ä½œæµå®šä¹‰æ³¨å†Œè¡¨
        self.workflow_definitions: Dict[str, WorkflowDefinition] = {}
        
        # æ´»è·ƒçš„å·¥ä½œæµæ‰§è¡Œ
        self.active_executions: Dict[str, WorkflowExecution] = {}
        
        # åˆå§‹åŒ–é¢„å®šä¹‰å·¥ä½œæµ
        self._initialize_predefined_workflows()
        
        logger.info("ğŸ—ï¸ å·¥ä½œæµç®¡ç†å™¨åˆå§‹åŒ–")

    async def initialize(self):
        """åˆå§‹åŒ–å·¥ä½œæµç®¡ç†å™¨"""
        try:
            logger.info("âœ… å·¥ä½œæµç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _initialize_predefined_workflows(self):
        """åˆå§‹åŒ–é¢„å®šä¹‰å·¥ä½œæµ"""
        # ç»¼åˆåˆ†æå·¥ä½œæµ
        comprehensive_workflow = WorkflowDefinition(
            workflow_id="comprehensive_analysis_v2",
            name="ç»¼åˆåˆ†æå·¥ä½œæµ v2.0",
            description="åŒ…å«æ•°æ®æ”¶é›†ã€å¤šç»´åˆ†æã€è¾©è®ºå’Œå†³ç­–çš„å®Œæ•´å·¥ä½œæµ",
            version="2.0",
            steps=[
                WorkflowStep(
                    step_id="data_preparation",
                    name="æ•°æ®å‡†å¤‡",
                    agent_types=["data_collector"],
                    parallel=False,
                    timeout=120
                ),
                WorkflowStep(
                    step_id="parallel_analysis",
                    name="å¹¶è¡Œåˆ†æ",
                    agent_types=["fundamentals_analyst", "market_analyst", "news_analyst"],
                    dependencies=["data_preparation"],
                    parallel=True,
                    timeout=300
                ),
                WorkflowStep(
                    step_id="sentiment_analysis",
                    name="æƒ…æ„Ÿåˆ†æ",
                    agent_types=["social_media_analyst"],
                    dependencies=["data_preparation"],
                    parallel=False,
                    optional=True,
                    timeout=180
                ),
                WorkflowStep(
                    step_id="research_debate",
                    name="ç ”ç©¶è¾©è®º",
                    agent_types=["bull_researcher", "bear_researcher"],
                    dependencies=["parallel_analysis"],
                    parallel=False,
                    timeout=240
                ),
                WorkflowStep(
                    step_id="risk_assessment",
                    name="é£é™©è¯„ä¼°è¾©è®º",
                    agent_types=["risky_debator", "safe_debator", "neutral_debator"],
                    dependencies=["research_debate"],
                    parallel=False,
                    timeout=180
                ),
                WorkflowStep(
                    step_id="management_review",
                    name="ç®¡ç†å±‚å®¡æ ¸",
                    agent_types=["research_manager", "risk_manager"],
                    dependencies=["risk_assessment"],
                    parallel=True,
                    timeout=200
                ),
                WorkflowStep(
                    step_id="final_decision",
                    name="æœ€ç»ˆå†³ç­–",
                    agent_types=["trader"],
                    dependencies=["management_review"],
                    parallel=False,
                    timeout=120
                )
            ],
            global_timeout=1800,
            failure_strategy="continue"
        )
        
        # å¿«é€Ÿåˆ†æå·¥ä½œæµ
        quick_workflow = WorkflowDefinition(
            workflow_id="quick_analysis_v2",
            name="å¿«é€Ÿåˆ†æå·¥ä½œæµ v2.0",
            description="å¿«é€Ÿçš„æŠ€æœ¯åˆ†æå’Œé£é™©è¯„ä¼°",
            version="2.0",
            steps=[
                WorkflowStep(
                    step_id="technical_analysis",
                    name="æŠ€æœ¯åˆ†æ",
                    agent_types=["market_analyst"],
                    parallel=False,
                    timeout=120
                ),
                WorkflowStep(
                    step_id="risk_check",
                    name="é£é™©æ£€æŸ¥",
                    agent_types=["risk_manager"],
                    dependencies=["technical_analysis"],
                    parallel=False,
                    timeout=90
                ),
                WorkflowStep(
                    step_id="quick_decision",
                    name="å¿«é€Ÿå†³ç­–",
                    agent_types=["trader"],
                    dependencies=["risk_check"],
                    parallel=False,
                    timeout=60
                )
            ],
            global_timeout=600,
            failure_strategy="stop"
        )
        
        # æ³¨å†Œå·¥ä½œæµ
        self.register_workflow(comprehensive_workflow)
        self.register_workflow(quick_workflow)
    
    def register_workflow(self, workflow: WorkflowDefinition):
        """æ³¨å†Œå·¥ä½œæµå®šä¹‰"""
        self.workflow_definitions[workflow.workflow_id] = workflow
        logger.info(f"ğŸ“‹ æ³¨å†Œå·¥ä½œæµ: {workflow.workflow_id} - {workflow.name}")
    
    async def start_workflow(
        self,
        workflow_id: str,
        context: Dict[str, Any],
        execution_id: Optional[str] = None
    ) -> str:
        """å¯åŠ¨å·¥ä½œæµæ‰§è¡Œ"""
        try:
            # è·å–å·¥ä½œæµå®šä¹‰
            workflow_def = self.workflow_definitions.get(workflow_id)
            if not workflow_def:
                raise ValueError(f"å·¥ä½œæµä¸å­˜åœ¨: {workflow_id}")
            
            # åˆ›å»ºæ‰§è¡Œå®ä¾‹
            if not execution_id:
                execution_id = str(uuid.uuid4())
            
            execution = WorkflowExecution(
                execution_id=execution_id,
                workflow_id=workflow_id,
                status=WorkflowStatus.PENDING,
                context=context
            )
            
            self.active_executions[execution_id] = execution
            
            # ä¿å­˜çŠ¶æ€
            await self.state_manager.save_workflow_state(execution_id, execution.__dict__)
            
            # å¯åŠ¨æ‰§è¡Œ
            asyncio.create_task(self._execute_workflow(execution_id))
            
            logger.info(f"ğŸš€ å¯åŠ¨å·¥ä½œæµ: {execution_id} - {workflow_id}")
            return execution_id
            
        except Exception as e:
            logger.error(f"âŒ å¯åŠ¨å·¥ä½œæµå¤±è´¥: {workflow_id} - {e}")
            raise
    
    async def _execute_workflow(self, execution_id: str):
        """æ‰§è¡Œå·¥ä½œæµ"""
        try:
            execution = self.active_executions.get(execution_id)
            if not execution:
                raise ValueError(f"å·¥ä½œæµæ‰§è¡Œä¸å­˜åœ¨: {execution_id}")
            
            workflow_def = self.workflow_definitions[execution.workflow_id]
            execution.status = WorkflowStatus.RUNNING
            
            logger.info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ: {execution_id}")
            
            # åˆ›å»ºæ­¥éª¤ä¾èµ–å›¾
            step_graph = self._build_dependency_graph(workflow_def.steps)
            
            # æŒ‰ä¾èµ–é¡ºåºæ‰§è¡Œæ­¥éª¤
            while execution.current_step_index < len(workflow_def.steps):
                # è·å–å¯æ‰§è¡Œçš„æ­¥éª¤
                ready_steps = self._get_ready_steps(workflow_def.steps, execution.completed_steps)
                
                if not ready_steps:
                    # æ£€æŸ¥æ˜¯å¦æœ‰å¤±è´¥çš„å¿…éœ€æ­¥éª¤
                    if self._has_failed_required_steps(workflow_def.steps, execution.failed_steps):
                        execution.status = WorkflowStatus.FAILED
                        execution.error = "å¿…éœ€æ­¥éª¤æ‰§è¡Œå¤±è´¥"
                        break
                    else:
                        # æ‰€æœ‰æ­¥éª¤éƒ½å·²å®Œæˆ
                        break
                
                # æ‰§è¡Œå‡†å¤‡å¥½çš„æ­¥éª¤
                await self._execute_steps_batch(execution, workflow_def, ready_steps)
                
                # æ›´æ–°çŠ¶æ€
                await self.state_manager.save_workflow_state(execution_id, execution.__dict__)
            
            # å®Œæˆå·¥ä½œæµ
            if execution.status == WorkflowStatus.RUNNING:
                execution.status = WorkflowStatus.COMPLETED
                execution.final_result = await self._aggregate_workflow_results(execution)
            
            execution.completed_at = datetime.now()
            
            # æœ€ç»ˆçŠ¶æ€ä¿å­˜
            await self.state_manager.save_workflow_state(execution_id, execution.__dict__)
            
            logger.info(f"âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆ: {execution_id} - {execution.status.value}")
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {execution_id} - {e}")
            if execution_id in self.active_executions:
                execution = self.active_executions[execution_id]
                execution.status = WorkflowStatus.FAILED
                execution.error = str(e)
                execution.completed_at = datetime.now()
    
    def _build_dependency_graph(self, steps: List[WorkflowStep]) -> Dict[str, List[str]]:
        """æ„å»ºæ­¥éª¤ä¾èµ–å›¾"""
        graph = {}
        for step in steps:
            graph[step.step_id] = step.dependencies.copy()
        return graph
    
    def _get_ready_steps(self, steps: List[WorkflowStep], completed_steps: List[str]) -> List[WorkflowStep]:
        """è·å–å‡†å¤‡æ‰§è¡Œçš„æ­¥éª¤"""
        ready_steps = []
        for step in steps:
            if (step.step_id not in completed_steps and 
                step.status == StepStatus.PENDING and
                all(dep in completed_steps for dep in step.dependencies)):
                ready_steps.append(step)
        return ready_steps
    
    def _has_failed_required_steps(self, steps: List[WorkflowStep], failed_steps: List[str]) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰å¿…éœ€æ­¥éª¤å¤±è´¥"""
        for step in steps:
            if step.step_id in failed_steps and not step.optional:
                return True
        return False
    
    async def _execute_steps_batch(
        self, 
        execution: WorkflowExecution, 
        workflow_def: WorkflowDefinition, 
        steps: List[WorkflowStep]
    ):
        """æ‰¹é‡æ‰§è¡Œæ­¥éª¤"""
        try:
            # åˆ†ç»„ï¼šå¹¶è¡Œæ­¥éª¤å’Œé¡ºåºæ­¥éª¤
            parallel_steps = [step for step in steps if step.parallel]
            sequential_steps = [step for step in steps if not step.parallel]
            
            # å…ˆæ‰§è¡Œå¹¶è¡Œæ­¥éª¤
            if parallel_steps:
                await self._execute_parallel_steps(execution, parallel_steps)
            
            # å†æ‰§è¡Œé¡ºåºæ­¥éª¤
            for step in sequential_steps:
                await self._execute_single_step(execution, step)
                
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡æ‰§è¡Œæ­¥éª¤å¤±è´¥: {e}")
            raise
    
    async def _execute_parallel_steps(self, execution: WorkflowExecution, steps: List[WorkflowStep]):
        """å¹¶è¡Œæ‰§è¡Œæ­¥éª¤"""
        try:
            tasks = []
            for step in steps:
                task = self._execute_single_step(execution, step)
                tasks.append(task)
            
            # ç­‰å¾…æ‰€æœ‰å¹¶è¡Œæ­¥éª¤å®Œæˆ
            await asyncio.gather(*tasks, return_exceptions=True)
            
        except Exception as e:
            logger.error(f"âŒ å¹¶è¡Œæ‰§è¡Œæ­¥éª¤å¤±è´¥: {e}")
            raise
    
    async def _execute_single_step(self, execution: WorkflowExecution, step: WorkflowStep):
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        try:
            step.status = StepStatus.RUNNING
            step.started_at = datetime.now()
            
            logger.info(f"ğŸ”§ æ‰§è¡Œæ­¥éª¤: {step.name} ({step.step_id})")
            
            # æ£€æŸ¥æ¡ä»¶
            if step.condition and not step.condition(execution.context):
                step.status = StepStatus.SKIPPED
                logger.info(f"â­ï¸ è·³è¿‡æ­¥éª¤: {step.name} (æ¡ä»¶ä¸æ»¡è¶³)")
                return
            
            # æ‰§è¡Œæ™ºèƒ½ä½“ä»»åŠ¡
            step_results = {}
            for agent_type in step.agent_types:
                try:
                    result = await self.collaboration_engine._create_agent_task(
                        agent_type, execution.context
                    )
                    step_results[agent_type] = result
                except Exception as e:
                    logger.error(f"âŒ æ™ºèƒ½ä½“ä»»åŠ¡å¤±è´¥: {agent_type} - {e}")
                    step_results[agent_type] = {
                        "status": "failed",
                        "error": str(e)
                    }
            
            # æ›´æ–°æ­¥éª¤ç»“æœ
            step.results = step_results
            step.status = StepStatus.COMPLETED
            step.completed_at = datetime.now()
            
            # æ›´æ–°æ‰§è¡ŒçŠ¶æ€
            execution.completed_steps.append(step.step_id)
            execution.step_results[step.step_id] = step_results
            
            logger.info(f"âœ… æ­¥éª¤å®Œæˆ: {step.name}")
            
        except Exception as e:
            step.status = StepStatus.FAILED
            step.error = str(e)
            step.completed_at = datetime.now()
            
            execution.failed_steps.append(step.step_id)
            
            logger.error(f"âŒ æ­¥éª¤å¤±è´¥: {step.name} - {e}")
            
            # æ ¹æ®å¤±è´¥ç­–ç•¥å¤„ç†
            if not step.optional:
                raise
    
    async def _aggregate_workflow_results(self, execution: WorkflowExecution) -> Dict[str, Any]:
        """èšåˆå·¥ä½œæµç»“æœ"""
        try:
            # æ”¶é›†æ‰€æœ‰æ­¥éª¤çš„ç»“æœ
            all_results = {}
            for step_id, step_results in execution.step_results.items():
                all_results[step_id] = step_results
            
            # ä½¿ç”¨å…±è¯†ç®—æ³•èšåˆæœ€ç»ˆç»“æœ
            from ..main import consensus_algorithm
            if consensus_algorithm:
                # æå–æ™ºèƒ½ä½“ç»“æœ
                agent_results = {}
                for step_results in execution.step_results.values():
                    for agent_type, result in step_results.items():
                        if result.get("status") == "completed":
                            agent_results[f"{agent_type}_{step_id}"] = result
                
                if agent_results:
                    consensus = await consensus_algorithm.reach_consensus(agent_results)
                    return {
                        "workflow_consensus": consensus,
                        "step_results": all_results,
                        "execution_summary": {
                            "total_steps": len(execution.step_results),
                            "completed_steps": len(execution.completed_steps),
                            "failed_steps": len(execution.failed_steps)
                        }
                    }
            
            return {
                "step_results": all_results,
                "execution_summary": {
                    "total_steps": len(execution.step_results),
                    "completed_steps": len(execution.completed_steps),
                    "failed_steps": len(execution.failed_steps)
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ èšåˆå·¥ä½œæµç»“æœå¤±è´¥: {e}")
            return {"error": str(e)}
    
    async def get_execution_status(self, execution_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€"""
        try:
            execution = self.active_executions.get(execution_id)
            if execution:
                return execution.__dict__
            
            # ä»çŠ¶æ€ç®¡ç†å™¨è·å–
            return await self.state_manager.get_workflow_state(execution_id)
            
        except Exception as e:
            logger.error(f"âŒ è·å–å·¥ä½œæµæ‰§è¡ŒçŠ¶æ€å¤±è´¥: {execution_id} - {e}")
            return None
    
    async def cancel_execution(self, execution_id: str) -> bool:
        """å–æ¶ˆå·¥ä½œæµæ‰§è¡Œ"""
        try:
            if execution_id in self.active_executions:
                execution = self.active_executions[execution_id]
                execution.status = WorkflowStatus.CANCELLED
                execution.completed_at = datetime.now()
                
                await self.state_manager.save_workflow_state(execution_id, execution.__dict__)
                
                logger.info(f"ğŸš« å–æ¶ˆå·¥ä½œæµæ‰§è¡Œ: {execution_id}")
                return True
            return False
            
        except Exception as e:
            logger.error(f"âŒ å–æ¶ˆå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {execution_id} - {e}")
            return False
    
    def get_workflow_definitions(self) -> Dict[str, WorkflowDefinition]:
        """è·å–æ‰€æœ‰å·¥ä½œæµå®šä¹‰"""
        return self.workflow_definitions.copy()
    
    async def health_check(self) -> bool:
        """å¥åº·æ£€æŸ¥"""
        try:
            return True
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµç®¡ç†å™¨å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # å–æ¶ˆæ‰€æœ‰æ´»è·ƒçš„æ‰§è¡Œ
            for execution_id in list(self.active_executions.keys()):
                await self.cancel_execution(execution_id)
            
            self.active_executions.clear()
            
            logger.info("âœ… å·¥ä½œæµç®¡ç†å™¨æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ å·¥ä½œæµç®¡ç†å™¨æ¸…ç†å¤±è´¥: {e}")
