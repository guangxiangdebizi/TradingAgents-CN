# ğŸ” TradingAgents æœåŠ¡å‘ç°æ¶æ„è®¾è®¡

## ğŸ“ **æ¦‚è¿°**

æœ¬æ–‡æ¡£å®šä¹‰äº†TradingAgentså¾®æœåŠ¡æ¶æ„ä¸­çš„æœåŠ¡å‘ç°æ–¹æ¡ˆï¼Œæ¶µç›–Kubernetesç¯å¢ƒä¸‹çš„æœåŠ¡å‘ç°ã€è´Ÿè½½å‡è¡¡ã€æ•…éšœè½¬ç§»å’Œæ€§èƒ½ä¼˜åŒ–ç­–ç•¥ã€‚

## ğŸ¯ **è®¾è®¡ç›®æ ‡**

### **æ ¸å¿ƒè¦æ±‚**
- âœ… **é«˜å¯ç”¨æ€§**: 99.9%+ æœåŠ¡å¯ç”¨æ€§
- âœ… **ä½å»¶è¿Ÿ**: æœåŠ¡å‘ç°å»¶è¿Ÿ < 10ms
- âœ… **è‡ªåŠ¨æ‰©å±•**: æ”¯æŒåŠ¨æ€æœåŠ¡å®ä¾‹ç®¡ç†
- âœ… **æ•…éšœéš”ç¦»**: å•ç‚¹æ•…éšœä¸å½±å“æ•´ä½“æœåŠ¡
- âœ… **è´Ÿè½½å‡è¡¡**: æ™ºèƒ½æµé‡åˆ†å‘
- âœ… **å¯è§‚æµ‹æ€§**: å®Œæ•´çš„ç›‘æ§å’Œè¿½è¸ª

### **æŠ€æœ¯çº¦æŸ**
- ä¸»è¦éƒ¨ç½²åœ¨Kubernetesç¯å¢ƒ
- æ”¯æŒæ··åˆäº‘å’Œå¤šé›†ç¾¤åœºæ™¯
- å…¼å®¹ç°æœ‰å¾®æœåŠ¡æ¶æ„
- æœ€å°åŒ–è¿ç»´å¤æ‚åº¦

## ğŸ—ï¸ **æ¶æ„è®¾è®¡**

### **æ•´ä½“æ¶æ„å›¾**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Service Discovery Layer                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Client    â”‚    â”‚   Client    â”‚    â”‚   Client    â”‚     â”‚
â”‚  â”‚ Load Balancerâ”‚    â”‚ Load Balancerâ”‚    â”‚ Load Balancerâ”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚        â”‚                  â”‚                  â”‚             â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                           â”‚                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚            Smart Service Discovery                â”‚     â”‚
â”‚  â”‚  â€¢ K8s Native Discovery                          â”‚     â”‚
â”‚  â”‚  â€¢ Intelligent Caching                           â”‚     â”‚
â”‚  â”‚  â€¢ Circuit Breaker                               â”‚     â”‚
â”‚  â”‚  â€¢ Health Monitoring                             â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                        â”‚                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚              Kubernetes Services              â”‚       â”‚
â”‚  â”‚                                               â”‚       â”‚
â”‚  â”‚  analysis-engine-service â”€â”€â”                 â”‚       â”‚
â”‚  â”‚  data-service â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€ Service     â”‚       â”‚
â”‚  â”‚  llm-service â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€ Registry    â”‚       â”‚
â”‚  â”‚  memory-service â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                        â”‚                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                Service Instances              â”‚       â”‚
â”‚  â”‚                                               â”‚       â”‚
â”‚  â”‚  [Pod1] [Pod2] [Pod3] ... [PodN]             â”‚       â”‚
â”‚  â”‚    â†•      â†•      â†•         â†•                 â”‚       â”‚
â”‚  â”‚  Auto-scaling based on metrics               â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ **æ ¸å¿ƒç»„ä»¶**

### **1. KubernetesåŸç”ŸæœåŠ¡å‘ç°**

#### **Serviceé…ç½®**
```yaml
# æ ‡å‡†ClusterIP Service
apiVersion: v1
kind: Service
metadata:
  name: analysis-engine-service
  labels:
    app: analysis-engine
    tier: compute
spec:
  selector:
    app: analysis-engine
  ports:
  - name: http
    port: 8005
    targetPort: 8005
    protocol: TCP
  type: ClusterIP
  sessionAffinity: None

---
# Headless Service (ç”¨äºæœåŠ¡å‘ç°)
apiVersion: v1
kind: Service
metadata:
  name: analysis-engine-headless
  labels:
    app: analysis-engine
    type: headless
spec:
  clusterIP: None
  selector:
    app: analysis-engine
  ports:
  - name: http
    port: 8005
    targetPort: 8005
```

#### **EndpointSliceç›‘æ§**
```yaml
# è‡ªåŠ¨åˆ›å»ºçš„EndpointSlice
apiVersion: discovery.k8s.io/v1
kind: EndpointSlice
metadata:
  name: analysis-engine-service-abc123
  labels:
    kubernetes.io/service-name: analysis-engine-service
addressType: IPv4
endpoints:
- addresses:
  - "10.244.1.10"
  - "10.244.2.15"
  - "10.244.3.20"
  conditions:
    ready: true
    serving: true
    terminating: false
ports:
- name: http
  port: 8005
  protocol: TCP
```

### **2. æ™ºèƒ½æœåŠ¡å‘ç°å®¢æˆ·ç«¯**

#### **æ ¸å¿ƒå®ç°**
```python
import asyncio
import aiohttp
import time
import random
from typing import List, Dict, Optional
from kubernetes import client, config, watch
from dataclasses import dataclass
from enum import Enum

class LoadBalanceAlgorithm(Enum):
    ROUND_ROBIN = "round_robin"
    LEAST_CONNECTIONS = "least_connections"
    WEIGHTED_RANDOM = "weighted_random"
    HEALTH_AWARE = "health_aware"

@dataclass
class ServiceInstance:
    """æœåŠ¡å®ä¾‹"""
    host: str
    port: int
    weight: int = 1
    healthy: bool = True
    connections: int = 0
    response_time: float = 0.0
    last_check: float = 0.0
    failure_count: int = 0

class SmartServiceDiscovery:
    """æ™ºèƒ½æœåŠ¡å‘ç°å®¢æˆ·ç«¯"""
    
    def __init__(self, namespace: str = "default", 
                 cache_ttl: int = 30,
                 algorithm: LoadBalanceAlgorithm = LoadBalanceAlgorithm.HEALTH_AWARE):
        self.namespace = namespace
        self.cache_ttl = cache_ttl
        self.algorithm = algorithm
        
        # åˆå§‹åŒ–K8så®¢æˆ·ç«¯
        try:
            config.load_incluster_config()  # Podå†…è¿è¡Œ
        except:
            config.load_kube_config()  # æœ¬åœ°å¼€å‘
        
        self.v1 = client.CoreV1Api()
        self.discovery_v1 = client.DiscoveryV1Api()
        
        # ç¼“å­˜å’ŒçŠ¶æ€
        self.service_cache: Dict[str, List[ServiceInstance]] = {}
        self.cache_timestamps: Dict[str, float] = {}
        self.circuit_breakers: Dict[str, Dict] = {}
        
        # ç›‘æ§æŒ‡æ ‡
        self.metrics = {
            "discovery_calls": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "service_calls": 0,
            "failures": 0
        }
    
    async def discover_service_instances(self, service_name: str, 
                                       force_refresh: bool = False) -> List[ServiceInstance]:
        """å‘ç°æœåŠ¡å®ä¾‹"""
        self.metrics["discovery_calls"] += 1
        
        # æ£€æŸ¥ç¼“å­˜
        if not force_refresh and self._is_cache_valid(service_name):
            self.metrics["cache_hits"] += 1
            return self.service_cache[service_name]
        
        self.metrics["cache_misses"] += 1
        
        try:
            # ä»K8sè·å–EndpointSlice
            endpoint_slices = self.discovery_v1.list_namespaced_endpoint_slice(
                namespace=self.namespace,
                label_selector=f"kubernetes.io/service-name={service_name}"
            )
            
            instances = []
            for slice_obj in endpoint_slices.items:
                for endpoint in slice_obj.endpoints:
                    if endpoint.conditions.ready:
                        for address in endpoint.addresses:
                            for port in slice_obj.ports:
                                instances.append(ServiceInstance(
                                    host=address,
                                    port=port.port,
                                    healthy=True
                                ))
            
            # æ›´æ–°ç¼“å­˜
            self.service_cache[service_name] = instances
            self.cache_timestamps[service_name] = time.time()
            
            return instances
            
        except Exception as e:
            logger.error(f"æœåŠ¡å‘ç°å¤±è´¥ {service_name}: {e}")
            # è¿”å›ç¼“å­˜çš„å®ä¾‹ï¼ˆå¦‚æœæœ‰ï¼‰
            return self.service_cache.get(service_name, [])
    
    def _is_cache_valid(self, service_name: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if service_name not in self.cache_timestamps:
            return False
        
        age = time.time() - self.cache_timestamps[service_name]
        return age < self.cache_ttl
    
    async def select_instance(self, service_name: str) -> Optional[ServiceInstance]:
        """é€‰æ‹©æœåŠ¡å®ä¾‹"""
        instances = await self.discover_service_instances(service_name)
        
        # è¿‡æ»¤å¥åº·å®ä¾‹
        healthy_instances = [i for i in instances if i.healthy and not self._is_circuit_open(i)]
        
        if not healthy_instances:
            return None
        
        # æ ¹æ®ç®—æ³•é€‰æ‹©å®ä¾‹
        if self.algorithm == LoadBalanceAlgorithm.ROUND_ROBIN:
            return self._round_robin_select(service_name, healthy_instances)
        elif self.algorithm == LoadBalanceAlgorithm.LEAST_CONNECTIONS:
            return min(healthy_instances, key=lambda x: x.connections)
        elif self.algorithm == LoadBalanceAlgorithm.WEIGHTED_RANDOM:
            return self._weighted_random_select(healthy_instances)
        elif self.algorithm == LoadBalanceAlgorithm.HEALTH_AWARE:
            return self._health_aware_select(healthy_instances)
        else:
            return random.choice(healthy_instances)
    
    def _health_aware_select(self, instances: List[ServiceInstance]) -> ServiceInstance:
        """å¥åº·æ„ŸçŸ¥é€‰æ‹©"""
        def score(instance: ServiceInstance) -> float:
            # ç»¼åˆè¯„åˆ†ï¼šå“åº”æ—¶é—´ + è¿æ¥æ•° + å¤±è´¥ç‡
            time_score = instance.response_time
            conn_score = instance.connections * 0.1
            failure_score = instance.failure_count * 2.0
            
            return time_score + conn_score + failure_score
        
        return min(instances, key=score)
    
    def _weighted_random_select(self, instances: List[ServiceInstance]) -> ServiceInstance:
        """åŠ æƒéšæœºé€‰æ‹©"""
        weights = [i.weight for i in instances]
        return random.choices(instances, weights=weights)[0]
    
    def _round_robin_select(self, service_name: str, instances: List[ServiceInstance]) -> ServiceInstance:
        """è½®è¯¢é€‰æ‹©"""
        if service_name not in self.circuit_breakers:
            self.circuit_breakers[service_name] = {"index": 0}
        
        index = self.circuit_breakers[service_name]["index"]
        selected = instances[index % len(instances)]
        self.circuit_breakers[service_name]["index"] = index + 1
        
        return selected
    
    def _is_circuit_open(self, instance: ServiceInstance) -> bool:
        """æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€"""
        # ç®€å•ç†”æ–­é€»è¾‘ï¼šè¿ç»­å¤±è´¥5æ¬¡åˆ™ç†”æ–­30ç§’
        if instance.failure_count >= 5:
            if time.time() - instance.last_check < 30:
                return True
            else:
                # é‡ç½®ç†”æ–­å™¨
                instance.failure_count = 0
                return False
        return False
    
    async def call_service(self, service_name: str, path: str = "/", 
                          method: str = "GET", data: Optional[Dict] = None,
                          timeout: int = 30, retries: int = 3) -> Dict:
        """è°ƒç”¨æœåŠ¡"""
        self.metrics["service_calls"] += 1
        
        last_exception = None
        
        for attempt in range(retries):
            instance = await self.select_instance(service_name)
            
            if not instance:
                raise Exception(f"æ²¡æœ‰å¯ç”¨çš„{service_name}å®ä¾‹")
            
            try:
                # å¢åŠ è¿æ¥è®¡æ•°
                instance.connections += 1
                start_time = time.time()
                
                url = f"http://{instance.host}:{instance.port}{path}"
                
                async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=timeout)) as session:
                    async with session.request(method, url, json=data) as response:
                        # è®°å½•å“åº”æ—¶é—´
                        instance.response_time = time.time() - start_time
                        instance.last_check = time.time()
                        
                        if response.status == 200:
                            # æˆåŠŸè°ƒç”¨ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
                            instance.failure_count = 0
                            result = await response.json()
                            return result
                        else:
                            raise aiohttp.ClientResponseError(
                                request_info=response.request_info,
                                history=response.history,
                                status=response.status
                            )
                            
            except Exception as e:
                # è®°å½•å¤±è´¥
                instance.failure_count += 1
                instance.last_check = time.time()
                last_exception = e
                
                if attempt < retries - 1:
                    # æŒ‡æ•°é€€é¿
                    await asyncio.sleep(2 ** attempt)
                
            finally:
                # å‡å°‘è¿æ¥è®¡æ•°
                instance.connections = max(0, instance.connections - 1)
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        self.metrics["failures"] += 1
        raise last_exception or Exception(f"è°ƒç”¨{service_name}å¤±è´¥")
    
    async def health_check_loop(self, interval: int = 10):
        """å¥åº·æ£€æŸ¥å¾ªç¯"""
        while True:
            try:
                for service_name, instances in self.service_cache.items():
                    for instance in instances:
                        try:
                            start_time = time.time()
                            url = f"http://{instance.host}:{instance.port}/health"
                            
                            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=5)) as session:
                                async with session.get(url) as response:
                                    instance.healthy = response.status == 200
                                    instance.response_time = time.time() - start_time
                                    
                        except Exception:
                            instance.healthy = False
                            instance.failure_count += 1
                
                await asyncio.sleep(interval)
                
            except Exception as e:
                logger.error(f"å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
                await asyncio.sleep(5)
    
    def get_metrics(self) -> Dict:
        """è·å–ç›‘æ§æŒ‡æ ‡"""
        cache_hit_rate = (
            self.metrics["cache_hits"] / max(1, self.metrics["discovery_calls"])
        )
        
        failure_rate = (
            self.metrics["failures"] / max(1, self.metrics["service_calls"])
        )
        
        return {
            **self.metrics,
            "cache_hit_rate": cache_hit_rate,
            "failure_rate": failure_rate,
            "cached_services": len(self.service_cache),
            "total_instances": sum(len(instances) for instances in self.service_cache.values())
        }

# å…¨å±€æœåŠ¡å‘ç°å®ä¾‹
_service_discovery: Optional[SmartServiceDiscovery] = None

def get_service_discovery(namespace: str = "default", 
                         algorithm: LoadBalanceAlgorithm = LoadBalanceAlgorithm.HEALTH_AWARE) -> SmartServiceDiscovery:
    """è·å–å…¨å±€æœåŠ¡å‘ç°å®ä¾‹"""
    global _service_discovery
    
    if _service_discovery is None:
        _service_discovery = SmartServiceDiscovery(namespace=namespace, algorithm=algorithm)
        # å¯åŠ¨å¥åº·æ£€æŸ¥
        asyncio.create_task(_service_discovery.health_check_loop())
    
    return _service_discovery
```

### **3. é…ç½®ç®¡ç†**

#### **ConfigMapé…ç½®**
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: service-discovery-config
  namespace: trading-system
data:
  config.yaml: |
    service_discovery:
      # åŸºç¡€é…ç½®
      namespace: trading-system
      cache_ttl: 30
      default_timeout: 30
      max_retries: 3
      
      # è´Ÿè½½å‡è¡¡é…ç½®
      load_balancing:
        algorithm: health_aware  # round_robin, least_connections, weighted_random, health_aware
        health_check:
          enabled: true
          interval: 10
          timeout: 5
          failure_threshold: 3
      
      # ç†”æ–­å™¨é…ç½®
      circuit_breaker:
        failure_threshold: 5
        recovery_timeout: 30
        half_open_max_calls: 3
      
      # æœåŠ¡é…ç½®
      services:
        analysis-engine:
          service_name: analysis-engine-service
          port: 8005
          health_path: /health
          weight: 1
          timeout: 300  # åˆ†æä»»åŠ¡è¶…æ—¶æ—¶é—´é•¿
          
        data-service:
          service_name: data-service
          port: 8003
          health_path: /health
          weight: 1
          timeout: 30
          
        llm-service:
          service_name: llm-service
          port: 8004
          health_path: /health
          weight: 1
          timeout: 60
          
        memory-service:
          service_name: memory-service
          port: 8006
          health_path: /health
          weight: 1
          timeout: 30
      
      # ç›‘æ§é…ç½®
      monitoring:
        metrics_enabled: true
        metrics_interval: 60
        log_level: INFO
        
      # ç¼“å­˜é…ç½®
      cache:
        enabled: true
        ttl: 30
        max_size: 1000
        cleanup_interval: 300
```

## ğŸ“Š **ä½¿ç”¨ç¤ºä¾‹**

### **1. åŸºç¡€ä½¿ç”¨**
```python
import asyncio
from service_discovery import get_service_discovery, LoadBalanceAlgorithm

async def main():
    # è·å–æœåŠ¡å‘ç°å®ä¾‹
    sd = get_service_discovery(
        namespace="trading-system",
        algorithm=LoadBalanceAlgorithm.HEALTH_AWARE
    )
    
    # è°ƒç”¨Analysis Engine
    try:
        result = await sd.call_service(
            service_name="analysis-engine",
            path="/api/v1/analysis/submit",
            method="POST",
            data={
                "stock_code": "AAPL",
                "analysis_type": "comprehensive"
            }
        )
        print(f"åˆ†æä»»åŠ¡æäº¤æˆåŠŸ: {result}")
        
    except Exception as e:
        print(f"è°ƒç”¨å¤±è´¥: {e}")
    
    # è·å–ç›‘æ§æŒ‡æ ‡
    metrics = sd.get_metrics()
    print(f"æœåŠ¡å‘ç°æŒ‡æ ‡: {metrics}")

if __name__ == "__main__":
    asyncio.run(main())
```

### **2. é«˜çº§ä½¿ç”¨**
```python
class TradingAgentsClient:
    """TradingAgentså®¢æˆ·ç«¯"""
    
    def __init__(self, namespace: str = "trading-system"):
        self.sd = get_service_discovery(namespace)
    
    async def submit_analysis(self, stock_code: str, analysis_type: str, priority: str = "normal"):
        """æäº¤åˆ†æä»»åŠ¡"""
        return await self.sd.call_service(
            service_name="analysis-engine",
            path="/api/v1/analysis/submit",
            method="POST",
            data={
                "stock_code": stock_code,
                "analysis_type": analysis_type
            },
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
    
    async def get_stock_data(self, symbol: str, period: str = "1y"):
        """è·å–è‚¡ç¥¨æ•°æ®"""
        return await self.sd.call_service(
            service_name="data-service",
            path="/api/v1/data/stock",
            method="GET",
            data={"symbol": symbol, "period": period}
        )
    
    async def search_memory(self, collection: str, query: str):
        """æœç´¢è®°å¿†"""
        return await self.sd.call_service(
            service_name="memory-service",
            path="/api/v1/memory/search",
            method="POST",
            data={
                "collection_name": collection,
                "query": query,
                "n_results": 3
            }
        )
    
    async def batch_analysis(self, stock_codes: List[str], max_concurrent: int = 5):
        """æ‰¹é‡åˆ†æ"""
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def analyze_single(code):
            async with semaphore:
                return await self.submit_analysis(code, "comprehensive")
        
        tasks = [analyze_single(code) for code in stock_codes]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        return results
```

## ğŸ”„ **éƒ¨ç½²å’Œè¿ç»´**

### **1. éƒ¨ç½²æ¸…å•**
```bash
# éƒ¨ç½²æœåŠ¡å‘ç°é…ç½®
kubectl apply -f service-discovery-config.yaml

# éƒ¨ç½²æœåŠ¡
kubectl apply -f analysis-engine-service.yaml
kubectl apply -f data-service.yaml
kubectl apply -f llm-service.yaml
kubectl apply -f memory-service.yaml

# éªŒè¯æœåŠ¡å‘ç°
kubectl get services -n trading-system
kubectl get endpointslices -n trading-system
```

### **2. ç›‘æ§å’Œå‘Šè­¦**
```yaml
# Prometheusç›‘æ§è§„åˆ™
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: service-discovery-alerts
spec:
  groups:
  - name: service-discovery
    rules:
    - alert: ServiceDiscoveryHighFailureRate
      expr: service_discovery_failure_rate > 0.1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "æœåŠ¡å‘ç°å¤±è´¥ç‡è¿‡é«˜"
        description: "æœåŠ¡å‘ç°å¤±è´¥ç‡ {{ $value }} è¶…è¿‡10%"
    
    - alert: ServiceInstancesLow
      expr: service_discovery_healthy_instances < 2
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "å¯ç”¨æœåŠ¡å®ä¾‹ä¸è¶³"
        description: "æœåŠ¡ {{ $labels.service }} åªæœ‰ {{ $value }} ä¸ªå¥åº·å®ä¾‹"
```

### **3. æ•…éšœæ’é™¤**
```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
kubectl get services -n trading-system
kubectl describe service analysis-engine-service -n trading-system

# æ£€æŸ¥ç«¯ç‚¹
kubectl get endpointslices -n trading-system
kubectl describe endpointslice analysis-engine-service-xxx -n trading-system

# æ£€æŸ¥PodçŠ¶æ€
kubectl get pods -l app=analysis-engine -n trading-system
kubectl logs -l app=analysis-engine -n trading-system

# æµ‹è¯•æœåŠ¡è¿é€šæ€§
kubectl run test-pod --image=curlimages/curl -it --rm -- /bin/sh
curl http://analysis-engine-service:8005/health
```

## ğŸ“ˆ **æ€§èƒ½ä¼˜åŒ–**

### **1. ç¼“å­˜ç­–ç•¥**
- **æœ¬åœ°ç¼“å­˜**: 30ç§’TTLï¼Œå‡å°‘K8s APIè°ƒç”¨
- **é¢„çƒ­ç¼“å­˜**: å¯åŠ¨æ—¶é¢„åŠ è½½å¸¸ç”¨æœåŠ¡
- **å¼‚æ­¥æ›´æ–°**: åå°å¼‚æ­¥æ›´æ–°ç¼“å­˜

### **2. è´Ÿè½½å‡è¡¡ä¼˜åŒ–**
- **å¥åº·æ„ŸçŸ¥**: ç»¼åˆå“åº”æ—¶é—´ã€è¿æ¥æ•°ã€å¤±è´¥ç‡
- **æƒé‡è°ƒæ•´**: æ ¹æ®å®ä¾‹æ€§èƒ½åŠ¨æ€è°ƒæ•´æƒé‡
- **äº²å’Œæ€§**: ä¼˜å…ˆé€‰æ‹©åŒèŠ‚ç‚¹/åŒåŒºåŸŸå®ä¾‹

### **3. ç›‘æ§æŒ‡æ ‡**
```python
# å…³é”®æŒ‡æ ‡
- service_discovery_calls_total: æœåŠ¡å‘ç°è°ƒç”¨æ¬¡æ•°
- service_discovery_cache_hit_rate: ç¼“å­˜å‘½ä¸­ç‡
- service_discovery_failure_rate: å¤±è´¥ç‡
- service_call_duration_seconds: æœåŠ¡è°ƒç”¨å»¶è¿Ÿ
- service_instances_healthy: å¥åº·å®ä¾‹æ•°
- circuit_breaker_state: ç†”æ–­å™¨çŠ¶æ€
```

## ğŸ¯ **æœ€ä½³å®è·µ**

### **1. æœåŠ¡è®¾è®¡**
- å®ç°æ ‡å‡†çš„`/health`å’Œ`/ready`ç«¯ç‚¹
- ä¼˜é›…å…³é—­ï¼Œå¤„ç†SIGTERMä¿¡å·
- åˆç†è®¾ç½®èµ„æºé™åˆ¶å’Œè¯·æ±‚

### **2. å®¢æˆ·ç«¯ä½¿ç”¨**
- ä½¿ç”¨è¿æ¥æ± å‡å°‘è¿æ¥å¼€é”€
- å®ç°æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥
- è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´

### **3. è¿ç»´ç®¡ç†**
- å®šæœŸæ£€æŸ¥æœåŠ¡å‘ç°æŒ‡æ ‡
- ç›‘æ§æœåŠ¡å®ä¾‹å¥åº·çŠ¶æ€
- åŠæ—¶å¤„ç†å‘Šè­¦å’Œå¼‚å¸¸

## ğŸš€ **å®æ–½è·¯çº¿å›¾**

### **é˜¶æ®µ1: åŸºç¡€å®æ–½ (1-2å‘¨)**
```
ç›®æ ‡: å®ç°K8såŸç”ŸæœåŠ¡å‘ç°
ä»»åŠ¡:
- [ ] éƒ¨ç½²K8s Serviceså’ŒEndpointSlices
- [ ] å®ç°åŸºç¡€æœåŠ¡å‘ç°å®¢æˆ·ç«¯
- [ ] é›†æˆåˆ°ç°æœ‰å¾®æœåŠ¡
- [ ] åŸºç¡€ç›‘æ§å’Œæ—¥å¿—

éªŒæ”¶æ ‡å‡†:
- æ‰€æœ‰æœåŠ¡å¯é€šè¿‡æœåŠ¡åè®¿é—®
- æœåŠ¡å‘ç°å»¶è¿Ÿ < 50ms
- åŸºç¡€è´Ÿè½½å‡è¡¡å·¥ä½œæ­£å¸¸
```

### **é˜¶æ®µ2: æ™ºèƒ½å¢å¼º (2-3å‘¨)**
```
ç›®æ ‡: æ·»åŠ æ™ºèƒ½è´Ÿè½½å‡è¡¡å’Œç¼“å­˜
ä»»åŠ¡:
- [ ] å®ç°å¤šç§è´Ÿè½½å‡è¡¡ç®—æ³•
- [ ] æ·»åŠ æœ¬åœ°ç¼“å­˜æœºåˆ¶
- [ ] é›†æˆå¥åº·æ£€æŸ¥
- [ ] å®ç°ç†”æ–­å™¨æ¨¡å¼

éªŒæ”¶æ ‡å‡†:
- ç¼“å­˜å‘½ä¸­ç‡ > 80%
- å¥åº·æ£€æŸ¥è‡ªåŠ¨æ•…éšœè½¬ç§»
- ç†”æ–­å™¨æ­£ç¡®å·¥ä½œ
```

### **é˜¶æ®µ3: é«˜çº§ç‰¹æ€§ (2-3å‘¨)**
```
ç›®æ ‡: å®Œå–„ç›‘æ§å’Œè¿ç»´èƒ½åŠ›
ä»»åŠ¡:
- [ ] å®Œæ•´çš„PrometheusæŒ‡æ ‡
- [ ] Grafanaç›‘æ§é¢æ¿
- [ ] å‘Šè­¦è§„åˆ™é…ç½®
- [ ] æ€§èƒ½ä¼˜åŒ–å’Œè°ƒä¼˜

éªŒæ”¶æ ‡å‡†:
- å®Œæ•´çš„ç›‘æ§ä½“ç³»
- è‡ªåŠ¨å‘Šè­¦æœºåˆ¶
- æ€§èƒ½è¾¾åˆ°è®¾è®¡ç›®æ ‡
```

### **é˜¶æ®µ4: ç”Ÿäº§å°±ç»ª (1-2å‘¨)**
```
ç›®æ ‡: ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å’ŒéªŒè¯
ä»»åŠ¡:
- [ ] ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- [ ] å‹åŠ›æµ‹è¯•éªŒè¯
- [ ] æ•…éšœæ¼”ç»ƒ
- [ ] æ–‡æ¡£å’ŒåŸ¹è®­

éªŒæ”¶æ ‡å‡†:
- é€šè¿‡ç”Ÿäº§ç¯å¢ƒéªŒè¯
- è¿ç»´å›¢é˜ŸåŸ¹è®­å®Œæˆ
- åº”æ€¥é¢„æ¡ˆå°±ç»ª
```

## ğŸ“š **å‚è€ƒèµ„æ–™**

### **ç›¸å…³æ–‡æ¡£**
- [Kubernetes Serviceå‘ç°å®˜æ–¹æ–‡æ¡£](https://kubernetes.io/docs/concepts/services-networking/service/)
- [EndpointSlice APIå‚è€ƒ](https://kubernetes.io/docs/reference/kubernetes-api/service-resources/endpoint-slice-v1/)
- [å¾®æœåŠ¡æ¶æ„è®¾è®¡æ–‡æ¡£](./microservices-architecture.md)
- [é«˜å¹¶å‘åˆ†ææ¶æ„æ–‡æ¡£](./concurrent-analysis-architecture.md)

### **æœ€ä½³å®è·µæŒ‡å—**
- [æœåŠ¡ç½‘æ ¼vsæœåŠ¡å‘ç°é€‰æ‹©æŒ‡å—](https://kubernetes.io/blog/2018/11/07/grpc-load-balancing-on-kubernetes-without-tears/)
- [Kubernetesç½‘ç»œæ•…éšœæ’é™¤](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/)
- [å¾®æœåŠ¡ç›‘æ§æœ€ä½³å®è·µ](https://prometheus.io/docs/practices/naming/)

### **å·¥å…·å’Œèµ„æº**
- [kubectlå‘½ä»¤å‚è€ƒ](https://kubernetes.io/docs/reference/kubectl/cheatsheet/)
- [Prometheusç›‘æ§é…ç½®](https://prometheus.io/docs/prometheus/latest/configuration/configuration/)
- [Grafanaé¢æ¿æ¨¡æ¿](https://grafana.com/grafana/dashboards/)

## ğŸ”§ **é™„å½•**

### **A. å®Œæ•´é…ç½®ç¤ºä¾‹**

#### **A.1 Kubernetes Manifests**
```yaml
# å®Œæ•´çš„æœåŠ¡é…ç½®æ–‡ä»¶
# æ–‡ä»¶: k8s/services/analysis-engine.yaml
apiVersion: v1
kind: Service
metadata:
  name: analysis-engine-service
  namespace: trading-system
  labels:
    app: analysis-engine
    component: compute
    version: v2.0
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: nlb
spec:
  selector:
    app: analysis-engine
  ports:
  - name: http
    port: 8005
    targetPort: http
    protocol: TCP
  - name: metrics
    port: 9090
    targetPort: metrics
    protocol: TCP
  type: ClusterIP
  sessionAffinity: None
  publishNotReadyAddresses: false
```

#### **A.2 ç›‘æ§é…ç½®**
```yaml
# Prometheus ServiceMonitor
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: service-discovery-monitor
  namespace: trading-system
spec:
  selector:
    matchLabels:
      app: analysis-engine
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

### **B. æ•…éšœæ’é™¤æ¸…å•**

#### **B.1 å¸¸è§é—®é¢˜**
```
é—®é¢˜: æœåŠ¡å‘ç°è¿”å›ç©ºåˆ—è¡¨
æ’æŸ¥:
1. æ£€æŸ¥Serviceæ˜¯å¦å­˜åœ¨: kubectl get svc
2. æ£€æŸ¥Selectoræ˜¯å¦åŒ¹é…: kubectl describe svc
3. æ£€æŸ¥Podæ ‡ç­¾: kubectl get pods --show-labels
4. æ£€æŸ¥EndpointSlice: kubectl get endpointslices

é—®é¢˜: è´Ÿè½½å‡è¡¡ä¸å‡åŒ€
æ’æŸ¥:
1. æ£€æŸ¥å®ä¾‹å¥åº·çŠ¶æ€
2. æŸ¥çœ‹è´Ÿè½½å‡è¡¡ç®—æ³•é…ç½®
3. æ£€æŸ¥å®ä¾‹æƒé‡è®¾ç½®
4. ç›‘æ§è¿æ¥æ•°åˆ†å¸ƒ

é—®é¢˜: æœåŠ¡è°ƒç”¨è¶…æ—¶
æ’æŸ¥:
1. æ£€æŸ¥ç½‘ç»œè¿é€šæ€§
2. æŸ¥çœ‹æœåŠ¡å“åº”æ—¶é—´
3. æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ
4. éªŒè¯è¶…æ—¶é…ç½®
```

#### **B.2 è°ƒè¯•å‘½ä»¤**
```bash
# æœåŠ¡å‘ç°è°ƒè¯•
kubectl get services -n trading-system -o wide
kubectl get endpointslices -n trading-system
kubectl describe endpointslice <name> -n trading-system

# ç½‘ç»œè¿é€šæ€§æµ‹è¯•
kubectl run debug-pod --image=nicolaka/netshoot -it --rm
nslookup analysis-engine-service.trading-system.svc.cluster.local
curl -v http://analysis-engine-service:8005/health

# æ—¥å¿—æŸ¥çœ‹
kubectl logs -l app=analysis-engine -n trading-system --tail=100
kubectl logs -l app=analysis-engine -n trading-system -f
```

### **C. æ€§èƒ½åŸºå‡†**

#### **C.1 æ€§èƒ½ç›®æ ‡**
```
æœåŠ¡å‘ç°å»¶è¿Ÿ: < 10ms (P99)
ç¼“å­˜å‘½ä¸­ç‡: > 90%
æœåŠ¡è°ƒç”¨æˆåŠŸç‡: > 99.9%
æ•…éšœè½¬ç§»æ—¶é—´: < 30s
è´Ÿè½½å‡è¡¡åå·®: < 10%
```

#### **C.2 å‹åŠ›æµ‹è¯•**
```python
# æ€§èƒ½æµ‹è¯•è„šæœ¬ç¤ºä¾‹
import asyncio
import time
from service_discovery import get_service_discovery

async def benchmark_service_discovery():
    sd = get_service_discovery()

    # é¢„çƒ­
    for _ in range(100):
        await sd.discover_service_instances("analysis-engine")

    # æ€§èƒ½æµ‹è¯•
    start_time = time.time()
    tasks = []

    for _ in range(1000):
        task = sd.discover_service_instances("analysis-engine")
        tasks.append(task)

    await asyncio.gather(*tasks)

    duration = time.time() - start_time
    qps = 1000 / duration

    print(f"QPS: {qps:.2f}")
    print(f"å¹³å‡å»¶è¿Ÿ: {duration/1000*1000:.2f}ms")

    # è·å–æŒ‡æ ‡
    metrics = sd.get_metrics()
    print(f"ç¼“å­˜å‘½ä¸­ç‡: {metrics['cache_hit_rate']:.2%}")

if __name__ == "__main__":
    asyncio.run(benchmark_service_discovery())
```

è¿™ä¸ªæœåŠ¡å‘ç°æ–¹æ¡ˆä¸ºTradingAgentsæä¾›äº†ä¼ä¸šçº§çš„æœåŠ¡æ²»ç†èƒ½åŠ›ï¼Œæ”¯æŒé«˜å¯ç”¨ã€é«˜æ€§èƒ½çš„å¾®æœåŠ¡é€šä¿¡ï¼ğŸš€
